{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tree segmentation with multitemporal Sentinel 1/2 imagery\n",
    "\n",
    "\n",
    "## Package Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm_notebook, tnrange\n",
    "import tensorflow as tf\n",
    "\n",
    "sess = tf.Session()\n",
    "from keras import backend as K\n",
    "K.set_session(sess)\n",
    "\n",
    "from time import sleep\n",
    "\n",
    "import keras\n",
    "from tensorflow.python.keras.layers import *\n",
    "from tensorflow.python.keras.layers import ELU\n",
    "from keras.losses import binary_crossentropy\n",
    "from tensorflow.python.ops import array_ops\n",
    "from tensorflow.python.keras.layers import Conv2D, Lambda, Dense, Multiply, Add\n",
    "from tensorflow.initializers import glorot_normal, lecun_normal\n",
    "from scipy.ndimage import median_filter\n",
    "from skimage.transform import resize\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from random import shuffle\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import os\n",
    "import random\n",
    "import itertools\n",
    "from tensorflow.contrib.framework import arg_scope\n",
    "from keras.regularizers import l1\n",
    "from tensorflow.layers import batch_normalization\n",
    "from tensorflow.python.util import deprecation as deprecation\n",
    "deprecation._PRINT_DEPRECATION_WARNINGS = False\n",
    "\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From /Users/jbrandt.terminal/Documents/GitHub/sentinel-tree-cover/src/layers/convgru.py:27: The name tf.nn.rnn_cell.RNNCell is deprecated. Please use tf.compat.v1.nn.rnn_cell.RNNCell instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%run ../src/layers/zoneout.py\n",
    "%run ../src/layers/adabound.py\n",
    "%run ../src/layers/convgru.py\n",
    "%run ../src/layers/dropblock.py\n",
    "%run ../src/layers/extra_layers.py\n",
    "%run ../src/layers/stochastic_weight_averaging.py\n",
    "%run ../src/preprocessing/indices.py\n",
    "%run ../src/preprocessing/slope.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ZONE_OUT_PROB = 0.90\n",
    "ACTIVATION_FUNCTION = 'swish'\n",
    "\n",
    "INITIAL_LR = 1e-3\n",
    "DROPBLOCK_MAXSIZE = 5\n",
    "\n",
    "N_CONV_BLOCKS = 1\n",
    "FINAL_ALPHA = 0.33\n",
    "LABEL_SMOOTHING = 0.03\n",
    "\n",
    "L2_REG = 0.\n",
    "BATCH_SIZE = 32\n",
    "MAX_DROPBLOCK = 0.6\n",
    "\n",
    "FRESH_START = True\n",
    "best_val = 0.2\n",
    "\n",
    "START_EPOCH = 1\n",
    "END_EPOCH = 100\n",
    "\n",
    "n_bands = 17\n",
    "initial_flt = 32\n",
    "mid_flt = 32 * 2\n",
    "high_flt = 32 * 2 * 2\n",
    "\n",
    "temporal_model = True\n",
    "input_size = 28\n",
    "output_size = 14"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom layer definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility blocks (Batch norm, cSSE, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sse_block(prevlayer, prefix):\n",
    "    '''Spatial excitation and channel squeeze layer.\n",
    "       Calculates a 1x1 convolution with sigmoid activation to create a \n",
    "       spatial map that is multiplied by the input layer\n",
    "\n",
    "         Parameters:\n",
    "          prevlayer (tf.Variable): input layer\n",
    "          prefix (str): prefix for tensorflow scope\n",
    "\n",
    "         Returns:\n",
    "          x (tf.Variable): output of the sse_block\n",
    "    '''\n",
    "    conv = Conv2D(1, (1, 1), padding=\"same\", kernel_initializer=tf.keras.initializers.he_normal(),\n",
    "                  activation='sigmoid', strides=(1, 1),\n",
    "                  name=prefix + \"_conv\")(prevlayer)\n",
    "    conv = Multiply(name=prefix + \"_mul\")([prevlayer, conv])\n",
    "    return conv\n",
    "\n",
    "\n",
    "class ReflectionPadding2D(Layer):\n",
    "    '''Adapted from https://github.com/mronta/CycleGAN-in-Keras/blob/master/reflection_padding.py\n",
    "       This is used instead of zero padding where possible to reduce boundary artifacts\n",
    "    '''\n",
    "    def __init__(self, padding=(1, 1), **kwargs):\n",
    "        self.padding = tuple(padding)\n",
    "        self.input_spec = [InputSpec(ndim=4)]\n",
    "        super(ReflectionPadding2D, self).__init__(**kwargs)\n",
    "\n",
    "    def compute_output_shape(self, s):\n",
    "        \"\"\" If you are using \"channels_last\" configuration\"\"\"\n",
    "        return (s[0], s[1] + 2 * self.padding[0], s[2] + 2 * self.padding[1], s[3])\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        w_pad,h_pad = self.padding\n",
    "        return tf.pad(x, [[0,0], [h_pad,h_pad], [w_pad,w_pad], [0,0] ], 'REFLECT')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conv GRU Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gru_block(inp, length, size, flt, scope, train, normalize = True):\n",
    "    '''Bidirectional convolutional GRU block with \n",
    "       zoneout and CSSE blocks in each time step\n",
    "\n",
    "         Parameters:\n",
    "          inp (tf.Variable): (B, T, H, W, C) layer\n",
    "          length (tf.Variable): (B, T) layer denoting number of\n",
    "                                steps per sample\n",
    "          size (int): kernel size of convolution\n",
    "          flt (int): number of convolution filters\n",
    "          scope (str): tensorflow variable scope\n",
    "          train (tf.Bool): flag to differentiate between train/test ops\n",
    "          normalize (bool): whether to compute layer normalization\n",
    "\n",
    "         Returns:\n",
    "          gru (tf.Variable): (B, H, W, flt*2) bi-gru output\n",
    "          steps (tf.Variable): (B, T, H, W, flt*2) output of each step\n",
    "    '''\n",
    "    with tf.variable_scope(scope):\n",
    "        print(f\"GRU input shape {inp.shape}, zoneout: {ZONE_OUT_PROB}\")\n",
    "        \n",
    "        # normalize is internal group normalization within the reset gate\n",
    "        # sse is internal SSE block within the state cell\n",
    "\n",
    "        cell_fw = ConvGRUCell(shape = size, filters = flt,\n",
    "                           kernel = [3, 3], padding = 'VALID', \n",
    "                           normalize = normalize, sse = True)\n",
    "        cell_bw = ConvGRUCell(shape = size, filters = flt,\n",
    "                           kernel = [3, 3], padding = 'VALID',\n",
    "                           normalize = normalize, sse = True)\n",
    "        \n",
    "        cell_fw = ZoneoutWrapper(\n",
    "           cell_fw, zoneout_drop_prob = ZONE_OUT_PROB, is_training = train)\n",
    "        cell_bw = ZoneoutWrapper(\n",
    "            cell_bw, zoneout_drop_prob = ZONE_OUT_PROB, is_training = train)\n",
    "        steps, out = convGRU(inp, cell_fw, cell_bw, length)\n",
    "        gru = tf.concat(out, axis = -1)\n",
    "        steps = tf.concat(steps, axis = -1)\n",
    "        print(f\"GRU block output shape {gru.shape}\")\n",
    "    return gru, steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conv blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partial_conv(x, channels, kernel=3, stride=1, use_bias=False, padding='SAME', scope='conv_0'):\n",
    "    \"\"\"Implementation of https://arxiv.org/abs/1804.07723\n",
    "       Partial conv is used in place of \"SAME\" padding to reduce boundary artifacts\n",
    "    \"\"\"\n",
    "    with tf.variable_scope(scope):\n",
    "        if padding.lower() == 'SAME'.lower() :\n",
    "            with tf.variable_scope('mask'):\n",
    "                _, h, w, _ = x.get_shape().as_list()\n",
    "\n",
    "                slide_window = kernel * kernel\n",
    "                mask = tf.ones(shape=[1, h, w, 1])\n",
    "\n",
    "                update_mask = tf.layers.conv2d(mask, filters=1,\n",
    "                                               kernel_size=kernel,\n",
    "                                               kernel_initializer=tf.constant_initializer(1.0),\n",
    "                                               strides=stride, \n",
    "                                               padding=padding, \n",
    "                                               use_bias=False,\n",
    "                                               trainable=False)\n",
    "\n",
    "                mask_ratio = slide_window / (update_mask + 1e-8)\n",
    "                update_mask = tf.clip_by_value(update_mask, 0.0, 1.0)\n",
    "                mask_ratio = mask_ratio * update_mask\n",
    "\n",
    "            with tf.variable_scope('x'):\n",
    "                x = tf.layers.conv2d(x, filters=channels,\n",
    "                                     kernel_size=kernel, \n",
    "                                     kernel_initializer=tf.keras.initializers.he_normal(),\n",
    "                                     strides=stride,\n",
    "                                     padding=padding, \n",
    "                                     use_bias=False)\n",
    "                x = x * mask_ratio\n",
    "\n",
    "                if use_bias:\n",
    "                    bias = tf.get_variable(\"bias\", \n",
    "                                           [channels],\n",
    "                                           initializer=tf.constant_initializer(0.0))\n",
    "\n",
    "                    x = tf.nn.bias_add(x, bias)\n",
    "                    x = x * update_mask\n",
    "\n",
    "        else :\n",
    "            x = tf.layers.conv2d(x, filters=channels,\n",
    "                                 kernel_size=kernel, \n",
    "                                 kernel_initializer=tf.keras.initializers.he_normal(),\n",
    "                                 strides=stride,\n",
    "                                 padding=padding,\n",
    "                                 use_bias=use_bias)\n",
    "\n",
    "        return x\n",
    "\n",
    "def conv_swish_gn(inp, \n",
    "                 is_training, \n",
    "                 kernel_size,\n",
    "                 scope,\n",
    "                 filters, \n",
    "                 keep_rate,\n",
    "                 stride = (1, 1),\n",
    "                 activation = True,\n",
    "                 use_bias = False,\n",
    "                 norm = True,\n",
    "                 dropblock = True,\n",
    "                 csse = True,\n",
    "                 weight_decay = None,\n",
    "                 block_size = 5,\n",
    "                 padding = \"SAME\",\n",
    "                 partial = True):\n",
    "    '''2D convolution, group normalization, SWISH activation, drop block, SSE. \n",
    "       DropBlock performs best when applied last, according to original paper.\n",
    "       This is the core CONV block for this model.\n",
    "\n",
    "         Parameters:\n",
    "          inp (tf.Variable): input layer\n",
    "          is_training (str): flag to differentiate between train/test ops\n",
    "          kernel_size (int): size of convolution\n",
    "          scope (str): tensorflow variable scope\n",
    "          filters (int): number of filters for convolution\n",
    "          keep_rate (float): Keep rate for dropblock\n",
    "          stride (tuple): Conv2D stride parameter\n",
    "          activation (bool): Whether or not to apply Swish activation\n",
    "          use_bias (bool): whether to use bias. Should always be false\n",
    "          norm (bool): whether or not to apply group normalization\n",
    "          dropblock (bool): whether or not to apply dropblock\n",
    "          csse (bool): whether or not to apply SSE block\n",
    "          weight_decay (bool): not currently implemented\n",
    "          block_size (int): Block size for dropblock\n",
    "          padding (str): padding parameter for conv2d\n",
    "          partial (bool): Whether or not to use partial conv or Conv2D\n",
    "\n",
    "         Returns:\n",
    "          conv (tf.Variable): output of the block\n",
    "        \n",
    "         References:\n",
    "          http://papers.nips.cc/paper/8271-dropblock-a-regularization-\n",
    "              method-for-convolutional-networks.pdf\n",
    "          https://arxiv.org/abs/1702.03275\n",
    "          \n",
    "    '''\n",
    "    \n",
    "    gn_flag = \"Group Norm\" if norm else \"\"\n",
    "    activation_flag = \"RELU\" if activation else \"Linear\"\n",
    "    sse_flag = \"SSE\" if csse else \"No SSE\"\n",
    "    bias_flag = \"Bias\" if use_bias else \"NoBias\"\n",
    "    drop_flag = \"DropBlock\" if dropblock else \"NoDrop\"\n",
    "        \n",
    "    print(f\"{scope} Conv: Kernel: {kernel_size}, {gn_flag}, {activation_flag}, {sse_flag}, {drop_flag}\")\n",
    "\n",
    "    with tf.variable_scope(scope + \"_conv\"):\n",
    "        if not partial:\n",
    "            conv = Conv2D(filters = filters, \n",
    "                          kernel_size = (kernel_size, kernel_size), \n",
    "                          strides = stride,\n",
    "                          activation = None,\n",
    "                          padding = 'valid',\n",
    "                          use_bias = use_bias,\n",
    "                          kernel_initializer = tf.keras.initializers.he_normal()\n",
    "                         )(inp)\n",
    "        if partial:\n",
    "            conv = partial_conv(inp, filters,\n",
    "                                kernel=kernel_size, \n",
    "                                stride=1, \n",
    "                                use_bias=False,\n",
    "                                padding=padding, \n",
    "                                scope = scope)\n",
    "    if activation:\n",
    "        conv = tf.nn.swish(conv)\n",
    "    if norm:\n",
    "        conv = group_norm(x = conv, scope = scope, G = 8)\n",
    "    if csse:\n",
    "        conv = sse_block(conv, \"csse_\" + scope)\n",
    "    if dropblock: \n",
    "        with tf.variable_scope(scope + \"_drop\"):\n",
    "            drop_block = DropBlock2D(keep_prob=keep_rate, block_size= block_size)\n",
    "            conv = drop_block(conv, is_training)\n",
    "    return conv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model definition\n",
    "\n",
    "## Placeholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Scale of 0 disables regularizer.\n"
     ]
    }
   ],
   "source": [
    "reg = tf.contrib.layers.l2_regularizer(0.)\n",
    "temporal_model = True\n",
    "input_size = 28\n",
    "n_bands = 17\n",
    "output_size = 14\n",
    "\n",
    "if temporal_model:\n",
    "    inp = tf.placeholder(tf.float32, shape=(None, 13, input_size, input_size, n_bands))\n",
    "    length = tf.placeholder_with_default(np.full((1,), 12), shape = (None,))\n",
    "else:\n",
    "    inp = tf.placeholder(tf.float32, shape=(None, input_size, input_size, n_bands))\n",
    "    \n",
    "labels = tf.placeholder(tf.float32, shape=(None, output_size, output_size))#, 1))\n",
    "keep_rate = tf.placeholder_with_default(1.0, ()) # For DropBlock\n",
    "is_training = tf.placeholder_with_default(False, (), 'is_training') # For DropBlock\n",
    "alpha = tf.placeholder(tf.float32, shape = ()) # For loss scheduling\n",
    "ft_lr = tf.placeholder_with_default(0.001, shape = ()) # For loss scheduling\n",
    "loss_weight = tf.placeholder_with_default(1.0, shape = ())\n",
    "beta_ = tf.placeholder_with_default(0.0, shape = ()) # For loss scheduling, not currently implemented"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "The model uses a UNet architecture where the encoder extracts increasingly abstract features and the decoder upsamples the features to the target resolution.\n",
    "\n",
    "The encoder consists of three blocks:\n",
    "\n",
    "- GRU: A bidirectional convolutional GRU with channel squeeze and spatial excitation, and group normalization, extracts 3x3 features from the multitemporal imagery\n",
    "- Conv1: A MaxPool-conv-swish-groupNorm-csse layer takes the output of the GRU (size 28) and reduces to size 12\n",
    "- Conv2: The output of the MaxPool-conv-swish-csse-DropBlock is a 4x4x128 encoded feature map\n",
    "\n",
    "The decoder consists of two blocks:\n",
    "\n",
    "- Upconv1: upsample-conv-swish-csse-concat-conv-swish\n",
    "- Upconv2: upsample-conv-swish-csse-concat-conv-swish\n",
    "- Output sigmoid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GRU input shape (?, 12, 28, 28, 17), zoneout: 0.9\n",
      "WARNING:tensorflow:From /Users/jbrandt.terminal/opt/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n",
      "(3, 3, 33, 32)\n",
      "(3, 3, 33, 32)\n",
      "GRU block output shape (?, 28, 28, 32)\n",
      "WARNING:tensorflow:From /Users/jbrandt.terminal/opt/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/jbrandt.terminal/opt/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "conv_median Conv: Kernel: 3, Group Norm, RELU, SSE, DropBlock\n",
      "Median conv: (?, 28, 28, 32)\n",
      "conv_concat Conv: Kernel: 3, Group Norm, RELU, SSE, DropBlock\n",
      "Concat: (?, 28, 28, 32)\n",
      "conv1 Conv: Kernel: 3, Group Norm, RELU, SSE, DropBlock\n",
      "Conv1: (?, 12, 12, 64)\n",
      "conv2 Conv: Kernel: 3, Group Norm, RELU, SSE, DropBlock\n",
      "Encoded (?, 4, 4, 128)\n",
      "up2 Conv: Kernel: 3, Group Norm, RELU, SSE, DropBlock\n",
      "(?, 8, 8, 64)\n",
      "up2_out Conv: Kernel: 3, Group Norm, RELU, SSE, DropBlock\n",
      "up3 Conv: Kernel: 3, Group Norm, RELU, SSE, DropBlock\n",
      "(?, 16, 16, 32)\n",
      "(?, 16, 16, 32)\n",
      "out Conv: Kernel: 3, Group Norm, RELU, SSE, NoDrop\n",
      "The output is (?, 8, 8, 64), with a receptive field of 1\n",
      "The output, sigmoid is (?, 14, 14, 1), with a receptive field of 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\nup4 = conv_swish_gn(inp = up3, is_training = is_training, stride = (1, 1),\\n                    kernel_size = 3, scope = \\'outregressor\\', filters = mid_flt, \\n                    keep_rate  = keep_rate, activation = True, use_bias = False, norm = True,\\n                    csse = True, dropblock =True, weight_decay = None, padding = \"SAME\")\\n#up4 = ReflectionPadding2D((1, 1,))(up4)\\nup5 = conv_swish_gn(inp = up4, is_training = is_training, stride = (1, 1),\\n                    kernel_size = 3, scope = \\'outregressor2\\', filters = mid_flt, \\n                    keep_rate  = keep_rate, activation = True, use_bias = False, norm = True,\\n                    csse = True, dropblock = False, weight_decay = None, padding = \"VALID\")\\n\\nregression = Conv2D(filters = 1,\\n            kernel_size = (1, 1),\\n            padding = \\'valid\\',\\n            activation = \\'linear\\',\\n            #bias_initializer = init,\\n           )(up5)\\n\\noutput = regression + fm\\noutput = tf.clip_by_value(output, 0, 1)\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# master modmel is 32, 64, 96, 230k paramms\n",
    "initial_flt = 32\n",
    "mid_flt = 32 * 2\n",
    "high_flt = 32 * 2 * 2\n",
    "INPUT_SIZE = 28\n",
    "SIZE_X = 28\n",
    "\n",
    "#inp = ReflectionPadding5D((1, 1))(inp)\n",
    "gru_input = inp[:, :12, ...]\n",
    "gru, steps = gru_block(inp = gru_input, length = length,\n",
    "                            size = [INPUT_SIZE, SIZE_X, ], # + 2 here for refleclt pad\n",
    "                            flt = initial_flt // 2,\n",
    "                            scope = 'down_16',\n",
    "                            train = is_training)\n",
    "with tf.variable_scope(\"gru_drop\"):\n",
    "    drop_block = DropBlock2D(keep_prob=keep_rate, block_size=4)\n",
    "    gru = drop_block(gru, is_training)\n",
    "    \n",
    "# Median conv\n",
    "median_input = inp[:, -1, ...]\n",
    "median_conv = conv_swish_gn(inp = median_input, is_training = is_training, stride = (1, 1),\n",
    "            kernel_size = 3, scope = 'conv_median', filters = initial_flt, \n",
    "            keep_rate = keep_rate, activation = True, use_bias = False, norm = True,\n",
    "            csse = True, dropblock = True, weight_decay = None)\n",
    "\n",
    "print(f\"Median conv: {median_conv.shape}\")\n",
    "\n",
    "concat1 = tf.concat([gru, median_conv], axis = -1)\n",
    "concat = conv_swish_gn(inp = concat1, is_training = is_training, stride = (1, 1),\n",
    "            kernel_size = 3, scope = 'conv_concat', filters = initial_flt,\n",
    "            keep_rate = keep_rate, activation = True, use_bias = False, norm = True,\n",
    "            csse = True, dropblock = True, weight_decay = None, padding = \"SAME\")\n",
    "print(f\"Concat: {concat.shape}\")\n",
    "\n",
    "    \n",
    "# MaxPool-conv-swish-GroupNorm-csse\n",
    "pool1 = MaxPool2D()(concat)\n",
    "conv1 = conv_swish_gn(inp = pool1, is_training = is_training, stride = (1, 1),\n",
    "            kernel_size = 3, scope = 'conv1', filters = mid_flt,\n",
    "            keep_rate = keep_rate, activation = True, use_bias = False, norm = True, padding = \"VALID\",\n",
    "            csse = True, dropblock = True, weight_decay = None)\n",
    "print(f\"Conv1: {conv1.shape}\")\n",
    "\n",
    "# MaxPool-conv-swish-csse-DropBlock\n",
    "pool2 = MaxPool2D()(conv1)\n",
    "conv2 = conv_swish_gn(inp = pool2, is_training = is_training, stride = (1, 1),\n",
    "            kernel_size = 3, scope = 'conv2', filters = high_flt, \n",
    "            keep_rate = keep_rate, activation = True, use_bias = False, norm = True,\n",
    "            csse = True, dropblock = True, weight_decay = None, block_size = 4, padding = \"VALID\")\n",
    "print(\"Encoded\", conv2.shape)\n",
    "\n",
    "# Decoder 4 - 8, upsample-conv-swish-csse-concat-conv-swish\n",
    "up2 = tf.keras.layers.UpSampling2D((2, 2), interpolation = 'nearest')(conv2)\n",
    "#up2 = ReflectionPadding2D((1, 1,))(up2)\n",
    "up2 = conv_swish_gn(inp = up2, is_training = is_training, stride = (1, 1),\n",
    "                    kernel_size = 3, scope = 'up2', filters = mid_flt, \n",
    "                    keep_rate = keep_rate, activation = True, use_bias = False, norm = True,\n",
    "                    csse = True, dropblock = True, weight_decay = None)\n",
    "conv1_crop = Cropping2D(2)(conv1)\n",
    "print(conv1_crop.shape)\n",
    "up2 = tf.concat([up2, conv1_crop], -1)\n",
    "#up2 = ReflectionPadding2D((1, 1,))(up2)\n",
    "up2 = conv_swish_gn(inp = up2, is_training = is_training, stride = (1, 1),\n",
    "                    kernel_size = 3, scope = 'up2_out', filters = mid_flt, \n",
    "                    keep_rate =  keep_rate, activation = True, use_bias = False, norm = True,\n",
    "                    csse = True, dropblock = True, weight_decay = None)\n",
    "\n",
    "# Decoder 8 - 14 upsample-conv-swish-csse-concat-conv-swish\n",
    "up3 = tf.keras.layers.UpSampling2D((2, 2), interpolation = 'nearest')(up2)\n",
    "#up3 = ReflectionPadding2D((1, 1,))(up3)\n",
    "up3 = conv_swish_gn(inp = up3, is_training = is_training, stride = (1, 1),\n",
    "                    kernel_size = 3, scope = 'up3', filters = initial_flt, \n",
    "                    keep_rate = keep_rate, activation = True, use_bias = False, norm = True,\n",
    "                    csse = True, dropblock = True, weight_decay = None)\n",
    "gru_crop = Cropping2D(6)(concat)\n",
    "print(up3.shape)\n",
    "print(gru_crop.shape)\n",
    "up3 = tf.concat([up3, gru_crop], -1)\n",
    "\n",
    "up3out = conv_swish_gn(inp = up3, is_training = is_training, stride = (1, 1),\n",
    "                    kernel_size = 3, scope = 'out', filters = initial_flt, \n",
    "                    keep_rate  = keep_rate, activation = True, use_bias = False, norm = True,\n",
    "                    csse = True, dropblock = False, weight_decay = None, padding = \"VALID\")\n",
    "\n",
    "\n",
    "#print(\"Initializing last sigmoid bias with -2.94 constant\")\n",
    "init = tf.constant_initializer([-np.log(0.7/0.3)]) # For focal loss\n",
    "print(f\"The output is {up2.shape}, with a receptive field of {1}\")\n",
    "fm = Conv2D(filters = 1,\n",
    "            kernel_size = (1, 1),\n",
    "            padding = 'valid',\n",
    "            activation = 'sigmoid',\n",
    "            bias_initializer = init,\n",
    "           )(up3out) # For focal loss\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finetune_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES,\"conv2d_15\") + \\\n",
    "                tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES,\"conv2d_17\") + \\\n",
    "                tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, \"outregressor\") + \\\n",
    "                tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, \"csse_outregressor\") + \\\n",
    "                tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, \"outregressor_drop\") + \\\n",
    "                tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, \"outregressor2\") + \\\n",
    "                tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, \"csse_outregressor2\") + \\\n",
    "                tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES,\"conv2d_13\") + \\\n",
    "                tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, \"csse_out\") + \\\n",
    "                tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, \"out\") + \\\n",
    "                tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, \"up3\") + \\\n",
    "                tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, \"up3_drop\") + \\\n",
    "                tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, \"csse_up3\") + \\\n",
    "                tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, \"up2_out\") + \\\n",
    "                tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, \"up2_out_drop\") + \\\n",
    "                tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, \"csse_up2_out\") + \\\n",
    "                tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, \"up2\") + \\\n",
    "                tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, \"up2_drop\") + \\\n",
    "                tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, \"csse_up2\")# + \\\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model has 329929 parameters\n"
     ]
    }
   ],
   "source": [
    "total_parameters = 0\n",
    "for variable in tf.trainable_variables():\n",
    "    shape = variable.get_shape()\n",
    "    variable_parameters = 1\n",
    "    for dim in shape:\n",
    "        variable_parameters *= dim.value\n",
    "    total_parameters += variable_parameters\n",
    "print(f\"This model has {total_parameters} parameters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.losses import binary_crossentropy\n",
    "import math\n",
    "from scipy.ndimage import distance_transform_edt as distance\n",
    "\n",
    "def weighted_bce_loss(y_true, y_pred, weight, mask = True, smooth = 0.03):\n",
    "    '''Calculates the weighted binary cross entropy loss between y_true and\n",
    "       y_pred with optional masking and smoothing for regularization\n",
    "       \n",
    "       For smoothing, we want to weight false positives as less important than\n",
    "       false negatives, so we smooth false negatives 2x as much. \n",
    "    \n",
    "         Parameters:\n",
    "          y_true (arr):\n",
    "          y_pred (arr):\n",
    "          weight (float):\n",
    "          mask (arr): DEPRECATED\n",
    "          smooth (float):\n",
    "\n",
    "         Returns:\n",
    "          loss (float):\n",
    "    '''\n",
    "    epsilon = 1e-7\n",
    "    y_pred = K.clip(y_pred, epsilon, 1. - epsilon)\n",
    "    y_true = K.clip(y_true, smooth, 1. - smooth)\n",
    "    logit_y_pred = K.log(y_pred / (1. - y_pred))\n",
    "    loss = tf.nn.weighted_cross_entropy_with_logits(\n",
    "        y_true,\n",
    "        logit_y_pred,\n",
    "        weight,\n",
    "    )\n",
    "\n",
    "    return loss\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def calc_dist_map(seg):\n",
    "    \n",
    "    \"\"\"\n",
    "    This is a modified version of surface loss to reduce\n",
    "    the loss importance of samples at the boundary. THe original\n",
    "    paper specifies a boundary loss of 0, but the low-resolution of\n",
    "    Sentinel data requires some amount of boundary importance, and\n",
    "    this function works well to accomplish that task\n",
    "    \"\"\"\n",
    "\n",
    "    res = np.zeros_like(seg)\n",
    "    posmask = seg.astype(np.bool)\n",
    "\n",
    "    mults = np.ones_like(seg)\n",
    "    ones = np.ones_like(seg)\n",
    "    for x in range(1, res.shape[0] -1 ):\n",
    "        for y in range(1, res.shape[0] - 1):\n",
    "            # If > 1 px distance, double the weight of the positive\n",
    "            # If == 1 px, half the weight of the negative\n",
    "            # This is important because the calc_mask fn\n",
    "            # leaves borders with 0 weight otherwise\n",
    "            if seg[x, y] == 1:\n",
    "                l = seg[x - 1, y]\n",
    "                r = seg[x + 1, y]\n",
    "                u = seg[x, y + 1]\n",
    "                d = seg[x, y - 1]\n",
    "                lu = seg[x - 1, y + 1]\n",
    "                ru = seg[x + 1, y + 1]\n",
    "                rd = seg[x + 1, y - 1]\n",
    "                ld = seg[x -1, y - 1]\n",
    "                \n",
    "                sums = (l + r + u + d)\n",
    "                sums2 = (l + r + u + d + lu + ru +rd + ld)\n",
    "                if sums >= 2:\n",
    "                    mults[x, y] = 2\n",
    "                if sums2 <= 1:\n",
    "                    ones[x - 1, y] = 0.5\n",
    "                    ones[x + 1, y] = 0.5\n",
    "                    ones[x, y + 1] = 0.5\n",
    "                    ones[x, y - 1] = 0.5\n",
    "                    ones[x - 1, y + 1] = 0.5\n",
    "                    ones[x + 1, y + 1] = 0.5\n",
    "                    ones[x + 1, y - 1] = 0.5\n",
    "                    ones[x -1, y - 1] = 0.5\n",
    "\n",
    "    if posmask.any():\n",
    "        negmask = ~posmask\n",
    "        res = distance(negmask) * negmask - (distance(posmask) - 1) * posmask\n",
    "        # When % = 1, 0 -> 1.75\n",
    "        # When % = 100, 0 -> 0\n",
    "        res = np.round(res, 0)\n",
    "        res[np.where(np.isclose(res, -.41421356, rtol = 1e-2))] = -1\n",
    "        res[np.where(res == -1)] = -1 * mults[np.where(res == -1)]\n",
    "        res[np.where(res == 0)] = -1  * mults[np.where(res == 0)]\n",
    "        # When % = 1, 1 -> 0\n",
    "        # When % = 100, 1 -> 1.75\n",
    "        res[np.where(res == 1)] = 1 * ones[np.where(res == 1)]\n",
    "        res[np.where(res == 1)] *= 0.67\n",
    "        \n",
    "    # Empirically capping the loss at -3 to 3 is better\n",
    "    res[np.where(res < -3)] = -3\n",
    "    res[np.where(res > 3)] = 3\n",
    "    if np.sum(seg) == 196:\n",
    "        res = np.ones_like(seg)\n",
    "        res *= -1\n",
    "    if np.sum(seg) == 0:\n",
    "        res = np.ones_like(seg)\n",
    "    return res\n",
    "\n",
    "\n",
    "def calc_dist_map_batch(y_true):\n",
    "    '''Applies calc_dist_map to each sample in an input batch\n",
    "    \n",
    "         Parameters:\n",
    "          y_true (arr):\n",
    "          \n",
    "         Returns:\n",
    "          loss (arr):\n",
    "    '''\n",
    "    y_true_numpy = y_true.numpy()\n",
    "    return np.array([calc_dist_map(y)\n",
    "                     for y in y_true_numpy]).astype(np.float32)\n",
    "\n",
    "\n",
    "def surface_loss(y_true, y_pred):\n",
    "    '''Calculates the mean surface loss for the input batch\n",
    "       by multiplying the distance map by y_pred\n",
    "    \n",
    "         Parameters:\n",
    "          y_true (arr):\n",
    "          y_pred (arr):\n",
    "          \n",
    "         Returns:\n",
    "          loss (arr):\n",
    "        \n",
    "         References:\n",
    "          https://arxiv.org/abs/1812.07032\n",
    "    '''\n",
    "    y_true_dist_map = tf.py_function(func=calc_dist_map_batch,\n",
    "                                     inp=[y_true],\n",
    "                                     Tout=tf.float32)\n",
    "    y_true_dist_map = tf.stack(y_true_dist_map, axis = 0)\n",
    "    multipled = y_pred * y_true_dist_map\n",
    "    loss = tf.reduce_mean(multipled, axis = (1, 2, 3))\n",
    "    return loss\n",
    "\n",
    "\n",
    "def bce_surface_loss(y_true, y_pred, alpha, weight, beta):\n",
    "    \n",
    "    \"\"\" Combines surface loss and binary cross entropy with a \n",
    "    alpha weighting factor. Beta is currently deprecated.\"\"\"\n",
    "    \n",
    "    bce = weighted_bce_loss(y_true = y_true, \n",
    "                             y_pred = y_pred, \n",
    "                             weight = weight,\n",
    "                             smooth = 0.03)\n",
    "\n",
    "    bce = tf.reduce_mean(bce, axis = (1, 2, 3))\n",
    "    surface = surface_loss(tf.cast(tf.math.greater(y_true, 0.10), tf.float32), y_pred)\n",
    "    surface = tf.reduce_mean(surface)\n",
    "\n",
    "    bce = tf.reduce_mean(bce)\n",
    "    bce = (1 - alpha) * bce\n",
    "    surface_portion = alpha * surface\n",
    "    result = bce + surface_portion\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting model with: \n",
      " 0.9 zone out \n",
      " 0.0 l2 \n",
      "0.001 initial LR \n",
      " 329929 parameters\n"
     ]
    }
   ],
   "source": [
    "def grad_norm(gradients):\n",
    "    norm = tf.compat.v1.norm(\n",
    "        tf.stack([\n",
    "            tf.compat.v1.norm(grad) for grad in gradients if grad is not None\n",
    "        ])\n",
    "    )\n",
    "    return norm\n",
    "\n",
    "FRESH_START = True\n",
    "print(f\"Starting model with: \\n {ZONE_OUT_PROB} zone out \\n {L2_REG} l2 \\n\"\n",
    "      f\"{INITIAL_LR} initial LR \\n {total_parameters} parameters\")  \n",
    "\n",
    "if FRESH_START:\n",
    "    # We use the Adabound optimizer\n",
    "    optimizer = AdaBoundOptimizer(INITIAL_LR, ft_lr)\n",
    "\n",
    "    train_loss = bce_surface_loss(tf.reshape(labels, (-1, 14, 14, 1)), fm,\n",
    "                                  weight = loss_weight, \n",
    "                             alpha = alpha, beta = beta_)\n",
    "\n",
    "    \n",
    "    # If there is any L2 regularization, add it. Current model does not use\n",
    "    l2_loss = tf.losses.get_regularization_loss()\n",
    "    if len(tf.losses.get_regularization_losses()) > 0:\n",
    "        train_loss = train_loss + l2_loss\n",
    "\n",
    "    \n",
    "    test_loss = bce_surface_loss(tf.reshape(labels, (-1, 14, 14, 1)),\n",
    "                            fm, weight = loss_weight, \n",
    "                            alpha = alpha, beta = beta_)\n",
    "    update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "    \n",
    "    with tf.control_dependencies(update_ops):\n",
    "        train_op = optimizer.minimize(train_loss, var_list = finetune_vars)   \n",
    "        #ft_op = ft_optimizer.minimize(train_loss)\n",
    "    \n",
    "    # The following code blocks are for sharpness aware minimization\n",
    "    # Adapted from https://github.com/sayakpaul/Sharpness-Aware-Minimization-TensorFlow\n",
    "    # For tensorflow 1.15\n",
    "    trainable_params = tf.trainable_variables()\n",
    "    gradients = optimizer.compute_gradients(loss=train_loss, var_list=None)\n",
    "    gradient_norm = grad_norm(gradients)\n",
    "    scale = 0.05 / (gradient_norm + 1e-12)\n",
    "    e_ws = []\n",
    "    for (grad, param) in gradients:\n",
    "        e_w = grad * scale\n",
    "        param.assign_add(e_w)\n",
    "        e_ws.append(e_w)\n",
    "\n",
    "    sam_gradients = optimizer.compute_gradients(loss=train_loss, var_list=None)\n",
    "    for (param, e_w) in zip(trainable_params, e_ws):\n",
    "        param.assign_sub(e_w)\n",
    "    train_step = optimizer.apply_gradients(sam_gradients)\n",
    "    \n",
    "    # Create a saver to save the model each epoch\n",
    "    init_op = tf.global_variables_initializer()\n",
    "    sess.run(init_op)\n",
    "    all_vars = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES)\n",
    "    all_vars = [x for x in all_vars if 'outregressor' not in x.name]\n",
    "    all_vars = [x for x in all_vars if 'conv2d_15' not in x.name]\n",
    "    all_vars = [x for x in all_vars if 'conv2d_17' not in x.name]\n",
    "    all_vars = [x for x in all_vars if 'outregressor2' not in x.name]\n",
    "    saver = tf.train.Saver(max_to_keep = 150, var_list = all_vars)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FRESH_START = False\n",
    "model_path  = \"../models/75-composite-masterfeb9/\"\n",
    "saver = tf.train.Saver(max_to_keep = 150, var_list = all_vars)\n",
    "if not os.path.exists(model_path):\n",
    "    os.makedirs(model_path)\n",
    "if os.path.isfile(f\"{model_path}metrics.npy\"):\n",
    "    metrics = np.load(f\"{model_path}metrics.npy\")\n",
    "    print(f\"Loading {model_path}metrics.npy\")\n",
    "else:\n",
    "    print(\"Starting anew\")\n",
    "    metrics = np.zeros((6, 300))\n",
    "\n",
    "if not FRESH_START:\n",
    "    path = model_path\n",
    "    saver.restore(sess, tf.train.latest_checkpoint(path))\n",
    "\n",
    "sess.run(tf.variables_initializer(new_varsinit))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_uninitialized(sess):\n",
    "    global_vars = tf.global_variables()\n",
    "    is_not_initialized = sess.run([tf.is_variable_initialized(var) for var in global_vars])\n",
    "    not_initialized_vars = [v for (v, f) in zip(global_vars, is_not_initialized) if not f]\n",
    "\n",
    "    if len(not_initialized_vars):\n",
    "        sess.run(tf.variables_initializer(not_initialized_vars))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementation of stochastic weight averaging\n",
    "\n",
    "\n",
    "        \n",
    "model_vars = tf.trainable_variables()\n",
    "swa = StochasticWeightAveraging()\n",
    "swa_op = swa.apply(var_list=model_vars)\n",
    "with tf.variable_scope('BackupVariables'):\n",
    "    # force tensorflow to keep theese new variables on the CPU ! \n",
    "    backup_vars = [tf.get_variable(var.op.name, dtype=var.value().dtype, trainable=False,\n",
    "                                   initializer=var.initialized_value())\n",
    "                   for var in model_vars]\n",
    "\n",
    "# operation to assign SWA weights to model\n",
    "swa_to_weights = tf.group(*(tf.assign(var, swa.average(var).read_value()) for var in model_vars))\n",
    "# operation to store model into backup variables\n",
    "save_weight_backups = tf.group(*(tf.assign(bck, var.read_value()) for var, bck in zip(model_vars, backup_vars)))\n",
    "# operation to get back values from backup variables to model\n",
    "restore_weight_backups = tf.group(*(tf.assign(var, bck.read_value()) for var, bck in zip(model_vars, backup_vars)))\n",
    "\n",
    "initialize_uninitialized(sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loading\n",
    "\n",
    "*  Load in CSV data from Collect Earth\n",
    "*  Reconstruct the X, Y grid for the Y data per sample\n",
    "*  Calculate remote sensing indices\n",
    "*  Stack X, Y, length data\n",
    "*  Apply median filter to DEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\noutliers = [61, 141, 218, 296, 365, 386, 594, 679, 712, 976, 1909, 2015]\\n#print([x for x in test_data['plotid'].iloc[outliers]])\\n\\ntrain_x = np.delete(train_x , outliers, 0)\\ntrain_y = np.delete(train_y, outliers, 0)\\ndata = data.drop(outliers, 0)\\ndata = data.reset_index(drop = True)\\n\\noutliers = [102]\\n#print([x for x in test_data['plotid'].iloc[outliers]])\\n\\ntrain_x = np.delete(train_x , outliers, 0)\\ntrain_y = np.delete(train_y, outliers, 0)\\ndata = data.drop(outliers, 0)\\ndata = data.reset_index(drop = True)\\n\\noutliers = [7, 8, 9, 11, 17, 18, 13, 27, 40, 44, 56, 83, 142, ]\\ntrain_x = np.delete(train_x , outliers, 0)\\ntrain_y = np.delete(train_y, outliers, 0)\\ndata = data.drop(outliers, 0)\\ndata = data.reset_index(drop = True)\\n\""
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import hickle as hkl\n",
    "\n",
    "train_x = hkl.load(\"../data/train/train_x.hkl\")\n",
    "train_y = hkl.load(\"../data/train/train_y.hkl\")\n",
    "data = pd.read_csv(\"../data/train/train_plot_ids.csv\")\n",
    "\n",
    "train_y = train_y #/ 255.\n",
    "if not isinstance(train_x.flat[0], np.floating):\n",
    "    assert np.max(train_x) > 1\n",
    "    train_x = train_x / 65535.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_db(x, min_db):\n",
    "    \"\"\"Converts sigma backscatter to decibel\"\"\"\n",
    "    x = 10 * np.log10(x + 1/65535)\n",
    "    x[x < -min_db] = -min_db\n",
    "    x = x + min_db\n",
    "    x = x / min_db\n",
    "    x = np.clip(x, 0, 1)\n",
    "    return x\n",
    "\n",
    "\n",
    "def grndvi(array):\n",
    "    nir = np.clip(array[..., 3], 0, 1)\n",
    "    green = np.clip(array[..., 1], 0, 1)\n",
    "    red = np.clip(array[..., 2], 0, 1)\n",
    "    denominator = (nir+(green+red)) + 1e-5\n",
    "    return (nir-(green+red)) / denominator\n",
    "\n",
    "\n",
    "def evi(x: np.ndarray, verbose: bool = False) -> np.ndarray:\n",
    "    '''\n",
    "    Calculates the enhanced vegetation index\n",
    "    2.5 x (08 - 04) / (08 + 6 * 04 - 7.5 * 02 + 1)\n",
    "    '''\n",
    "\n",
    "    BLUE = x[..., 0]\n",
    "    GREEN = x[..., 1]\n",
    "    RED = x[..., 2]\n",
    "    NIR = x[..., 3]\n",
    "    evis = 2.5 * ( (NIR-RED) / (NIR + (6*RED) - (7.5*BLUE) + 1))\n",
    "    evis = np.clip(evis, -1.5, 1.5)\n",
    "    return evis\n",
    "\n",
    "\n",
    "def msavi2(x: np.ndarray, verbose: bool = False) -> np.ndarray:\n",
    "    '''\n",
    "    Calculates the modified soil-adjusted vegetation index 2\n",
    "    (2 * NIR + 1 - sqrt((2*NIR + 1)^2 - 8*(NIR-RED)) / 2\n",
    "    '''\n",
    "    BLUE = x[..., 0]\n",
    "    GREEN = x[..., 1]\n",
    "    RED = np.clip(x[..., 2], 0, 1)\n",
    "    NIR = np.clip(x[..., 3], 0, 1)\n",
    "\n",
    "    msavis = (2 * NIR + 1 - np.sqrt( (2*NIR+1)**2 - 8*(NIR-RED) )) / 2\n",
    "    return msavis\n",
    "\n",
    "\n",
    "def bi(x: np.ndarray, verbose: bool = False) -> np.ndarray:\n",
    "    \"\"\"Bare soil index\"\"\"\n",
    "    B11 = np.clip(x[..., 8], 0, 1)\n",
    "    B4 = np.clip(x[..., 2], 0, 1)\n",
    "    B8 = np.clip(x[..., 3], 0, 1)\n",
    "    B2 = np.clip(x[..., 0], 0, 1)\n",
    "    bis = ((B11 + B4) - (B8 + B2)) / ((B11 + B4) + (B8 + B2))\n",
    "    return bis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jbrandt.terminal/opt/anaconda3/envs/tf/lib/python3.7/site-packages/ipykernel_launcher.py:54: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    }
   ],
   "source": [
    "train_x[..., -1] = convert_to_db(train_x[..., -1], 22)\n",
    "train_x[..., -2] = convert_to_db(train_x[..., -2], 22)\n",
    "\n",
    "indices = np.zeros((train_x.shape[0], 12, 28, 28, 4), dtype = np.float32)\n",
    "indices[..., 0] = evi(train_x)\n",
    "indices[..., 1] = bi(train_x)\n",
    "indices[..., 2] = msavi2(train_x)\n",
    "indices[..., 3] = grndvi(train_x)\n",
    "\n",
    "train_x = np.concatenate([train_x, indices], axis = -1)\n",
    "med = np.median(train_x, axis = 1)\n",
    "med = med[:, np.newaxis, :, :, :]\n",
    "train_x = np.concatenate([train_x, med], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jbrandt.terminal/opt/anaconda3/envs/tf/lib/python3.7/site-packages/ipykernel_launcher.py:14: TqdmDeprecationWarning: Please use `tqdm.notebook.trange` instead of `tqdm.tnrange`\n",
      "  \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11372816069249de8beba283bea05f6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "min_all = [0.006576638437476157, 0.0162050812542916, 0.010040436408026246, \n",
    "           0.013351644159609368, 0.01965362020294499, 0.014229037918669413, \n",
    "           0.015289539940489814, 0.011993591210803388, 0.008239871824216068, \n",
    "           0.006546120393682765, 0.0, 0.0, 0.0, -0.1409399364817101, \n",
    "           -0.4973397113668104, -0.09731556326714398, -0.7193834232943873]\n",
    "\n",
    "max_all = [0.2691233691920348, 0.3740291447318227, 0.5171435111009385, 0.6027466239414053,\n",
    "           0.5650263218127718, 0.5747005416952773, 0.5933928435187305, 0.6034943160143434, \n",
    "           0.7472037842374304, 0.7000076295109483, 0.509269855802243, 0.948334642387533, \n",
    "           0.6729257769285485, 0.8177635298774327, 0.35768999002433816, 0.7545951919107605, \n",
    "           0.7602693339366691]\n",
    "\n",
    "# Min all, and max all are the 0.1 and 99.9 percentiles of each band\n",
    "for band in tnrange(0, train_x.shape[-1]):\n",
    "    mins = min_all[band]\n",
    "    maxs = max_all[band]\n",
    "    train_x[..., band] = np.clip(train_x[..., band], mins, maxs)\n",
    "    midrange = (maxs + mins) / 2\n",
    "    rng = maxs - mins\n",
    "    standardized = (train_x[..., band] - midrange) / (rng / 2)\n",
    "    train_x[..., band] = standardized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jbrandt.terminal/opt/anaconda3/envs/tf/lib/python3.7/site-packages/ipykernel_launcher.py:4: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "outliers = np.argwhere(np.sum(np.isnan(train_x), axis = (1, 2, 3, 4)) > 0).flatten()\n",
    "train_x = np.delete(train_x , outliers, 0)\n",
    "train_y = np.delete(train_y, outliers, 0)\n",
    "data = data.drop(outliers, 0)\n",
    "data = data.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and process test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hickle as hkl\n",
    "\"\"\"\n",
    "test_x = hkl.load(\"../data/train/train_x.hkl\")\n",
    "test_y = hkl.load(\"../data/train/train_y.hkl\")\n",
    "test_data = pd.read_csv(\"../data/train/train_plot_ids.csv\")\n",
    "\n",
    "test_y = test_y / 255.\n",
    "\n",
    "test_x = np.delete(test_x, 11, -1)\n",
    "\n",
    "if not isinstance(test_x.flat[0], np.floating):\n",
    "    assert np.max(test_x) > 1\n",
    "    test_x = test_x / 65535.\n",
    "    \n",
    "test_x[..., -1] = convert_to_db(test_x[..., -1], 22)\n",
    "test_x[..., -2] = convert_to_db(test_x[..., -2], 22)\n",
    "\n",
    "indices = np.empty((test_x.shape[0], 12, 28, 28, 4))\n",
    "indices[..., 0] = evi(test_x)\n",
    "indices[..., 1] = bi(test_x)\n",
    "indices[..., 2] = msavi2(test_x)\n",
    "indices[..., 3] = grndvi(test_x)\n",
    "\n",
    "test_x = np.concatenate([test_x, indices], axis = -1)\n",
    "med = np.median(test_x, axis = 1)\n",
    "med = med[:, np.newaxis, :, :, :]\n",
    "test_x = np.concatenate([test_x, med], axis = 1)\n",
    "\n",
    "below_1 = [i for i, val in enumerate(test_x[..., :-2]) if np.min(val) < -1.66]\n",
    "above_1 = [i for i, val in enumerate(test_x[..., :-2]) if np.max(val) > 1.66]\n",
    "nans = [i for i, val in enumerate(test_x) if np.sum(np.isnan(val)) > 0]\n",
    "outliers = below_1 + above_1 + nans\n",
    "outliers = list(set(outliers))\n",
    "outliers = [61, 141, 218, 296, 365, 386, 594, 679, 712, 976, 1909, 2015]\n",
    "print([x for x in test_data['plotid'].iloc[outliers]])\n",
    "\n",
    "test_x = np.delete(test_x, outliers, 0)\n",
    "test_y = np.delete(test_y, outliers, 0)\n",
    "test_data = test_data.drop(outliers, 0)\n",
    "test_data = test_data.reset_index(drop = True)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfor band in range(0, test_x.shape[-1]):\\n    mins = min_all[band]\\n    maxs = max_all[band]\\n    test_x[..., band] = np.clip(test_x[..., band], mins, maxs)\\n    midrange = (maxs + mins) / 2\\n    rng = maxs - mins\\n    standardized = (test_x[..., band] - midrange) / (rng / 2)\\n    test_x[..., band] = standardized\\n'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "for band in range(0, test_x.shape[-1]):\n",
    "    mins = min_all[band]\n",
    "    maxs = max_all[band]\n",
    "    test_x[..., band] = np.clip(test_x[..., band], mins, maxs)\n",
    "    midrange = (maxs + mins) / 2\n",
    "    rng = maxs - mins\n",
    "    standardized = (test_x[..., band] - midrange) / (rng / 2)\n",
    "    test_x[..., band] = standardized\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Equibatch creation\n",
    "\n",
    "The modelling approach uses equibatch sampling to ensure that there is a near constant standard deviation of the percent tree cover in the output labels for each batch. This helps ensure that the model performs equally well across gradients of tree cover, by mitigating the random possibility that many batches in a row near the end of sampling may be randomly biased towards a tree cover range.\n",
    "\n",
    "It was actually very important for stable training to implement equibatch as the risk of diverging based on bad batches was very high without equibatch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_f1_score_at_tolerance(true, pred, tolerance = 1):\n",
    "    \"\"\"Because of coregistration errors, we evaluate the model\n",
    "    where false positives/negatives must be >1px away from a true positive\n",
    "    \"\"\"\n",
    "    fp = 0\n",
    "    tp = 0\n",
    "    fn = 0\n",
    "    \n",
    "    tp = np.zeros_like(true)\n",
    "    fp = np.zeros_like(true)\n",
    "    fn = np.zeros_like(true)\n",
    "    \n",
    "    for x in range(true.shape[0]):\n",
    "        for y in range(true.shape[1]):\n",
    "            min_x = np.max([0, x-1])\n",
    "            min_y = np.max([0, y-1])\n",
    "            max_y = np.min([true.shape[0], y+2])\n",
    "            max_x = np.min([true.shape[0], x+2])\n",
    "            if true[x, y] == 1:\n",
    "                if np.sum(pred[min_x:max_x, min_y:max_y]) > 0:\n",
    "                    tp[x, y] = 1\n",
    "                else:\n",
    "                    fn[x, y] = 1\n",
    "            if pred[x, y] == 1:\n",
    "                if np.sum(true[min_x:max_x, min_y:max_y]) > 0:\n",
    "                    if true[x, y] == 1:\n",
    "                        tp[x, y] = 1\n",
    "                else:\n",
    "                    fp[x, y] = 1                \n",
    "                \n",
    "    return np.sum(tp), np.sum(fp), np.sum(fn)\n",
    "\n",
    "def calculate_metrics(al = 0.4, canopy_thresh = 100):\n",
    "    '''Calculates the following metrics\n",
    "       \n",
    "         - Loss\n",
    "         - F1\n",
    "         - Precision\n",
    "         - Recall\n",
    "         - Dice\n",
    "         - Mean surface distance\n",
    "         - Average error\n",
    "    \n",
    "         Parameters:\n",
    "          al (float):\n",
    "          canopy_thresh (int)\n",
    "          \n",
    "         Returns:\n",
    "          val_loss (float):\n",
    "          best_dice (float):\n",
    "          error (float):\n",
    "    '''\n",
    "    start_idx = 0\n",
    "    stop_idx = len(test_x)\n",
    "    best_f1, best_thresh, relaxed_f1 = 0, 0, 0\n",
    "    preds, trues, vls = [], [], []\n",
    "\n",
    "    test_ids = [x for x in range(len(test_x))]\n",
    "    for test_sample in test_ids[start_idx:stop_idx]:\n",
    "        if np.sum(test_y[test_sample]) < ((canopy_thresh/100) * 197):\n",
    "            x_input = test_x[test_sample].reshape(1, 13, 28, 28, n_bands)\n",
    "            x_median_input = calc_median_input(x_input)\n",
    "            y, vl = sess.run([fm, test_loss], feed_dict={inp: x_input,\n",
    "                                                          length: np.full((1,), 12),\n",
    "                                                          is_training: False,\n",
    "                                                          labels: test_y[test_sample].reshape(1, 14, 14),\n",
    "                                                          loss_weight: 1.0,\n",
    "                                                          alpha: 0.33,\n",
    "                                                          })\n",
    "            preds.append(y.reshape((14, 14)))\n",
    "            vls.append(vl)\n",
    "            trues.append(test_y[test_sample].reshape((14, 14)))\n",
    "            \n",
    "    # These threshes are just for ROC\n",
    "    for thresh in range(7, 9):\n",
    "        tps_relaxed = np.empty((len(preds), ))\n",
    "        fps_relaxed = np.empty((len(preds), ))\n",
    "        fns_relaxed = np.empty((len(preds), ))\n",
    "        abs_error = np.empty((len(preds), ))\n",
    "        \n",
    "        for sample in range(len(preds)):\n",
    "            pred = np.copy(preds[sample])\n",
    "            true = trues[sample]\n",
    "        \n",
    "            pred[np.where(pred >= thresh*0.05)] = 1\n",
    "            pred[np.where(pred < thresh*0.05)] = 0\n",
    "            \n",
    "            true_s = np.sum(true[1:-1])\n",
    "            pred_s = np.sum(pred[1:-1])\n",
    "            abs_error[sample] = abs(true_s - pred_s)\n",
    "            tp_relaxed, fp_relaxed, fn_relaxed = compute_f1_score_at_tolerance(true, pred)\n",
    "            tps_relaxed[sample] = tp_relaxed\n",
    "            fps_relaxed[sample] = fp_relaxed\n",
    "            fns_relaxed[sample] = fn_relaxed                   \n",
    "            \n",
    "        oa_error = np.mean(abs_error)\n",
    "        precision_r = np.sum(tps_relaxed) / (np.sum(tps_relaxed) + np.sum(fps_relaxed))\n",
    "        recall_r = np.sum(tps_relaxed) / (np.sum(tps_relaxed) + np.sum(fns_relaxed))\n",
    "        f1_r = 2*((precision_r* recall_r) / (precision_r + recall_r))\n",
    "        \n",
    "        if f1_r > best_f1:\n",
    "            best_f1 = f1_r\n",
    "            p = precision_r\n",
    "            r = recall_r\n",
    "            error = oa_error\n",
    "            best_thresh = thresh*0.05\n",
    "\n",
    "    print(f\"Val loss: {np.around(np.mean(vls), 3)}\"\n",
    "          f\" Thresh: {np.around(best_thresh, 2)}\"\n",
    "          f\" F1: {np.around(best_f1, 3)} R: {np.around(p, 3)} P: {np.around(r, 3)}\"\n",
    "          f\" Error: {np.around(error, 3)}\")\n",
    "    return np.mean(vls), best_f1, error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below code block implements cut mix where random samples are spliced together where the output labels have similar tree cover distributions (within the same kmeans cluster). Not super necessary but does give a small performance improvement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_batch(batch_ids, batch_size):\n",
    "    '''Performs random flips and rotations of the X and Y\n",
    "       data, cut mix, and random splicing of the temporal data\n",
    "    \n",
    "         Parameters:\n",
    "          batch_ids (list):\n",
    "          batch_size (int):\n",
    "          \n",
    "         Returns:\n",
    "          x_batch (arr):\n",
    "          y_batch (arr):\n",
    "    '''\n",
    "    x = train_x[batch_ids]\n",
    "    samples_to_median = np.random.randint(0, 12, size=(batch_size, 6))\n",
    "    n_samples = np.random.randint(2, 7, size=(batch_size))\n",
    "    for samp in range(batch_size):\n",
    "        samps = samples_to_median[samp, :np.random.randint(2, 6)]\n",
    "        lower_samp = np.min(samps)\n",
    "        upper_samp = np.max(samps)\n",
    "        med_samp = np.median(x[samp, samps], axis = 0)\n",
    "        \n",
    "        x[samp, :lower_samp] = x[samp, lower_samp]\n",
    "        x[samp, upper_samp:] = x[samp, upper_samp]\n",
    "        x[samp, -1, ...] = med_samp\n",
    "        \n",
    "    y = train_y[batch_ids]\n",
    "    x_batch = np.zeros_like(x)\n",
    "    y_batch = np.zeros_like(y)\n",
    "    \n",
    "    flips = np.random.choice(np.array([0, 1, 2, 3]), batch_size, replace = True)\n",
    "    for i in range(x.shape[0]):\n",
    "        current_flip = flips[i]\n",
    "        if current_flip == 0:\n",
    "            x_batch[i] = x[i]\n",
    "            y_batch[i] = y[i]\n",
    "        if current_flip == 1:\n",
    "            x_batch[i] = np.flip(x[i], 1)\n",
    "            y_batch[i] = np.flip(y[i], 0)\n",
    "        if current_flip == 2:\n",
    "            x_batch[i] = np.flip(x[i], [2, 1])\n",
    "            y_batch[i] = np.flip(y[i], [1, 0])\n",
    "        if current_flip == 3:\n",
    "            x_batch[i] = np.flip(x[i], 2)\n",
    "            y_batch[i] = np.flip(y[i], 1)\n",
    "\n",
    "    y_batch = y_batch.reshape((batch_size, 14, 14))\n",
    "    return x_batch, y_batch\n",
    "\n",
    "x_batch_test, y_batch_test = augment_batch([x for x in range(4)], 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x864 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "start = 75\n",
    "end = 125\n",
    "f, ((c1r1, c1r2), (c2r1, c2r2)) = plt.subplots(2, 2, sharey=False)\n",
    "f.set_size_inches(15, 12)\n",
    "\n",
    "c1r1.set_title(f\"Train loss - {model_path}\")\n",
    "l1 = sns.scatterplot(y = metrics[0, start:end], x = np.arange(start, end), ax = c1r1)\n",
    "l1.set(ylim=(0.30, .40))\n",
    "\n",
    "c1r2.set_title(\"F1 score\")\n",
    "f =sns.scatterplot(y = metrics[5, start:end], x = np.arange(start, end), ax = c1r2)\n",
    "f.set(ylim=(0.84, .91))\n",
    "\n",
    "c2r1.set_title(\"Test loss\")\n",
    "l = sns.scatterplot(y = metrics[1, start:end], x = np.arange(start, end), ax = c2r1)\n",
    "l.set(ylim=(0.140, .165)) \n",
    "\n",
    "c2r2.set_title(\"Absolute % error\")\n",
    "e = sns.scatterplot(y = metrics[2, start:end] / 2, x = np.arange(start, end), ax = c2r2)\n",
    "e.set(ylim=(2.2, 3.5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "891\n",
      "starting epoch 115, alpha: 0.33, beta: 0.0, drop: 0.9 Learning rate: 0.1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4802a37c786a417e9716f80206bd746a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/111 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jbrandt.terminal/opt/anaconda3/envs/tf/lib/python3.7/site-packages/ipykernel_launcher.py:48: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 115: Loss 0.14100000262260437\n",
      "891\n",
      "starting epoch 116, alpha: 0.33, beta: 0.0, drop: 0.9 Learning rate: 0.1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e04db6c85294f8fafb417f501c32bde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/111 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 116: Loss 0.13600000739097595\n",
      "891\n",
      "starting epoch 117, alpha: 0.33, beta: 0.0, drop: 0.9 Learning rate: 0.1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "deb8fa138ba048b39c983c2bcf04b606",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/111 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 117: Loss 0.12800000607967377\n",
      "891\n",
      "starting epoch 118, alpha: 0.33, beta: 0.0, drop: 0.9 Learning rate: 0.1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "021e96592c4e48daa1782e9a9bc56f15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/111 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 118: Loss 0.12700000405311584\n",
      "891\n",
      "starting epoch 119, alpha: 0.33, beta: 0.0, drop: 0.9 Learning rate: 0.1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c4fd8f10d0649fc8bde383e5f9d5458",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/111 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 119: Loss 0.14300000667572021\n",
      "891\n",
      "starting epoch 120, alpha: 0.33, beta: 0.0, drop: 0.9 Learning rate: 0.1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c941af9feffe460f913af154fc23f826",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/111 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 120: Loss 0.13600000739097595\n",
      "891\n",
      "starting epoch 121, alpha: 0.33, beta: 0.0, drop: 0.9 Learning rate: 0.1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "809e48d2265446f7aa1a9a440a877067",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/111 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 121: Loss 0.125\n",
      "891\n",
      "starting epoch 122, alpha: 0.33, beta: 0.0, drop: 0.9 Learning rate: 0.1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc6807705f7c4142a617b56a330c19a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/111 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 122: Loss 0.12399999797344208\n",
      "891\n",
      "starting epoch 123, alpha: 0.33, beta: 0.0, drop: 0.9 Learning rate: 0.1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05f886657d864c66a6376172a1a19a82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/111 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 123: Loss 0.11800000071525574\n",
      "891\n",
      "starting epoch 124, alpha: 0.33, beta: 0.0, drop: 0.9 Learning rate: 0.1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42da936889b441f49e8886ae82658aa2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/111 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 124: Loss 0.11299999803304672\n",
      "891\n",
      "starting epoch 125, alpha: 0.33, beta: 0.0, drop: 0.9 Learning rate: 0.1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "293a08ee13554eb6a669a79f57ad51d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/111 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 125: Loss 0.09700000286102295\n",
      "891\n",
      "starting epoch 126, alpha: 0.33, beta: 0.0, drop: 0.9 Learning rate: 0.1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15cc28e98e7f487ea2705562e56b973d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/111 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m~/opt/anaconda3/envs/tf/lib/python3.7/site-packages/numpy/core/numerictypes.py\u001b[0m in \u001b[0;36missubclass_\u001b[0;34m(arg1, arg2)\u001b[0m\n\u001b[1;32m    320\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 321\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0missubclass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    322\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: issubclass() arg 1 must be a class",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-130-828dc7e272a4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotebook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtnrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandomize\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mbatch_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandomize\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0mx_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maugment_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m         \u001b[0;31m#print(np.sum(np.sum(y_batch, axis = (1, 2)) <= 2))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         opt, tr = sess.run([op, loss],\n",
      "\u001b[0;32m<ipython-input-26-c3211825a489>\u001b[0m in \u001b[0;36maugment_batch\u001b[0;34m(batch_ids, batch_size)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mlower_samp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mupper_samp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mmed_samp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmedian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msamp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamps\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msamp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mlower_samp\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msamp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlower_samp\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mmedian\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf/lib/python3.7/site-packages/numpy/lib/function_base.py\u001b[0m in \u001b[0;36mmedian\u001b[0;34m(a, axis, out, overwrite_input, keepdims)\u001b[0m\n\u001b[1;32m   3654\u001b[0m     \"\"\"\n\u001b[1;32m   3655\u001b[0m     r, k = _ureduce(a, func=_median, axis=axis, out=out,\n\u001b[0;32m-> 3656\u001b[0;31m                     overwrite_input=overwrite_input)\n\u001b[0m\u001b[1;32m   3657\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3658\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf/lib/python3.7/site-packages/numpy/lib/function_base.py\u001b[0m in \u001b[0;36m_ureduce\u001b[0;34m(a, func, **kwargs)\u001b[0m\n\u001b[1;32m   3562\u001b[0m         \u001b[0mkeepdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3564\u001b[0;31m     \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3565\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf/lib/python3.7/site-packages/numpy/lib/function_base.py\u001b[0m in \u001b[0;36m_median\u001b[0;34m(a, axis, out, overwrite_input)\u001b[0m\n\u001b[1;32m   3706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3707\u001b[0m     \u001b[0;31m# Check if the array contains any nan's\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3708\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0missubdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minexact\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0msz\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3709\u001b[0m         \u001b[0;31m# warn and return nans like mean would\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3710\u001b[0m         \u001b[0mrout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpart\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf/lib/python3.7/site-packages/numpy/core/numerictypes.py\u001b[0m in \u001b[0;36missubdtype\u001b[0;34m(arg1, arg2)\u001b[0m\n\u001b[1;32m    415\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m     \"\"\"\n\u001b[0;32m--> 417\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0missubclass_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgeneric\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    418\u001b[0m         \u001b[0marg1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0missubclass_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgeneric\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf/lib/python3.7/site-packages/numpy/core/numerictypes.py\u001b[0m in \u001b[0;36missubclass_\u001b[0;34m(arg1, arg2)\u001b[0m\n\u001b[1;32m    319\u001b[0m     \"\"\"\n\u001b[1;32m    320\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 321\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0missubclass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    322\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "\n",
    "best_val = 0.72\n",
    "fine_tune = False\n",
    "ft_epochs = 0\n",
    "BATCH_SIZE = 8\n",
    "\n",
    "\n",
    "\n",
    "for i in range(76, 200):\n",
    "    if i >= 175:\n",
    "        SWA = True# set to true to start SWA\n",
    "    else:\n",
    "        SWA = False\n",
    "    al = FINAL_ALPHA\n",
    "    ft_learning_rate = .1\n",
    "    be = 0.0\n",
    "    test_al = al\n",
    "    op = train_op# if fine_tune else train_op\n",
    "        \n",
    "    train_ids = [x for x in range(len(train_y))]\n",
    "    np.random.shuffle(train_ids)\n",
    "    randomize = train_ids\n",
    "\n",
    "    print(f\"starting epoch {i}, \" \n",
    "          f\"alpha: {al}, beta: {be}, \"\n",
    "          f\"drop: {np.max(((1. - (i * 0.005)), 0.9))} \"\n",
    "          f\"Learning rate: {ft_learning_rate}\"\n",
    "         )\n",
    "    \n",
    "    loss = train_loss\n",
    "    losses = []\n",
    "    \n",
    "    for k in tqdm.notebook.tnrange(int(len(randomize) // BATCH_SIZE)):\n",
    "        batch_ids = randomize[k*BATCH_SIZE:(k+1)*BATCH_SIZE]\n",
    "        x_batch, y_batch = augment_batch(batch_ids, BATCH_SIZE)\n",
    "        #print(np.sum(np.sum(y_batch, axis = (1, 2)) <= 2))\n",
    "        opt, tr = sess.run([op, loss],\n",
    "                          feed_dict={inp: x_batch,\n",
    "                                     length: np.full((BATCH_SIZE,), 12),\n",
    "                                     labels: y_batch,\n",
    "                                     is_training: True,\n",
    "                                     loss_weight: 1.0,\n",
    "                                     keep_rate: 0.95,#np.max(((1. - (i * 0.01)), MAX_DROPBLOCK)),\n",
    "                                     alpha: al,\n",
    "                                     beta_: be,\n",
    "                                     ft_lr: ft_learning_rate,\n",
    "                                     })\n",
    "        losses.append(tr)\n",
    "    \n",
    "    print(f\"Epoch {i}: Loss {np.around(np.mean(losses[:-1]), 3)}\")\n",
    "    if SWA:\n",
    "        sess.run(swa_op)\n",
    "        sess.run(save_weight_backups)\n",
    "        sess.run(swa_to_weights)\n",
    "        \n",
    "    #metrics[0, i] = np.mean(losses[:-1])\n",
    "    #val_loss, f1, error = calculate_metrics('all', al = test_al, canopy_thresh = 75)\n",
    "    #metrics[1, i] = val_loss\n",
    "    #metrics[2, i] = error\n",
    "    #metrics[5, i] = f1\n",
    "    \n",
    "    #if f1 < (best_val - 0.002):\n",
    "    #    ft_epochs += 1\n",
    "        \n",
    "    #if f1 > (best_val - 0.02):\n",
    "    #    print(f\"Saving model with {f1}\")\n",
    "        #np.save(f\"{model_path}metrics.npy\", metrics)\n",
    "        #os.mkdir(f\"{model_path}{str(i)}-{str(f1*100)[:2]}-{str(f1*100)[3]}/\")\n",
    "        #save_path = saver.save(sess, f\"{model_path}/{str(i)}-{str(f1*100)[:2]}-{str(f1*100)[3]}/model\")\n",
    "     #   if f1 > best_val:\n",
    "     #       best_val = f1\n",
    "    if SWA:\n",
    "        sess.run(restore_weight_backups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sess.run(swa_to_weights)\n",
    "saver = tf.train.Saver(max_to_keep = 150)\n",
    "#os.mkdir(f\"../models/plantation/\")\n",
    "save_path = saver.save(sess, f\"../models/plantation/model\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test prediction visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "start =0\n",
    "#test_ids = [x for x in range(0, len(test_x))]\n",
    "\n",
    "def multiplot(matrices, nrows = 2, ncols = 4):\n",
    "    '''Docstring\n",
    "    \n",
    "         Parameters:\n",
    "          matrices (list):\n",
    "          nrows (int):\n",
    "          \n",
    "         Returns:\n",
    "          None\n",
    "    '''\n",
    "    fig, axs = plt.subplots(ncols=4, nrows = nrows)\n",
    "    fig.set_size_inches(18, 4*nrows)\n",
    "    to_iter = [[x for x in range(i, i + ncols + 1)] for i in range(0, nrows*ncols, ncols)]\n",
    "    for r in range(1, nrows + 1):\n",
    "        min_i = min(to_iter[r-1])\n",
    "        max_i = max(to_iter[r-1])\n",
    "        for i, matrix in enumerate(matrices[min_i:max_i]):\n",
    "            sns.heatmap(data = matrix, ax = axs[r - 1, i], vmin = 0, vmax = 0.9, cbar = False)\n",
    "            axs[r - 1, i].set_xlabel(\"\")\n",
    "            axs[r - 1, i].set_ylabel(\"\")\n",
    "            axs[r - 1, i].set_yticks([])\n",
    "            axs[r - 1, i].set_xticks([])\n",
    "    plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ids = [x for x in range(test_x.shape[0])]\n",
    "matrix_ids = np.arange(start, start + 8, 1)\n",
    "matrix_ids = test_ids[matrix_ids]\n",
    "preds, trues = [], []\n",
    "\n",
    "for i in matrix_ids:\n",
    "    idx = i\n",
    "    x_input = test_x[idx].reshape(1, 13, 28, 28, n_bands)\n",
    "    median_input = calc_median_input(x_input)\n",
    "    y = sess.run([fm], feed_dict={inp: x_input,\n",
    "                                  length: np.full((1,), 12),\n",
    "                                  is_training: False,\n",
    "                                  })\n",
    "    y = np.array(y).reshape(14, 14)\n",
    "    print(i, (list(test_data.iloc[idx, 1])[0], list(test_data.iloc[idx, 2])[0]), diffs[i[0]])\n",
    "    preds.append(y)\n",
    "    y2 = np.copy(y)\n",
    "    true = tes\n",
    "    t_y[idx].reshape(14, 14)\n",
    "    trues.append(true)\n",
    "\n",
    "to_plot = trues[0:4] + preds[0:4] + trues[4:] + preds[4:]\n",
    "multiplot(to_plot, nrows = 4, ncols = 4)\n",
    "\n",
    "start = start + 8 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train prediction visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[48 49 50 51 52 53 54 55]\n",
      "0.01 3.951264 25.548304\n",
      "0.11 3.849909 25.592321\n",
      "0.32 3.7119527 25.786663\n",
      "-0.02 -6.710809 35.841248\n",
      "-0.08 3.551974 16.800766\n",
      "0.14 13.452668 120.437386\n",
      "-0.07 15.500703 -87.10512\n",
      "0.52 34.427288 92.709656\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x1152 with 16 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_ids = np.array([x for x in range(train_x.shape[0])])\n",
    "\n",
    "matrix_ids = np.arange(start, start + 8, 1)\n",
    "matrix_ids = train_ids[matrix_ids]\n",
    "preds, trues = [], []\n",
    "\n",
    "print(matrix_ids)\n",
    "for i in matrix_ids:\n",
    "    idx = i\n",
    "    x_input = train_x[idx].reshape(1, 13, 28, 28, n_bands)\n",
    "    y = sess.run([fm], feed_dict={inp: x_input,\n",
    "                                  length: np.full((1,), 12),\n",
    "                                  is_training: False,\n",
    "                                    })\n",
    "    y = np.array(y).reshape(14, 14)  \n",
    "    preds.append(y)\n",
    "    true = train_y[idx].reshape(14, 14)\n",
    "    trues.append(true)\n",
    "    print(np.\n",
    "          around(np.mean(y) - np.mean(true), 2), data.iloc[i].lat, data.iloc[i].lon)\n",
    "    \n",
    "start += 8\n",
    "to_plot = trues[0:4] + preds[0:4] + trues[4:] + preds[4:]\n",
    "multiplot(to_plot, nrows = 4, ncols = 4)\n",
    "# 2006, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
