{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tree segmentation with multitemporal Sentinel 1/2 imagery\n",
    "\n",
    "## John Brandt\n",
    "## February 2022\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook contains the TensorFlow model training and prediction. The notebook uses tensorflow 1.15.1 and additionally relies on Keras.\n",
    "\n",
    "## References\n",
    "\n",
    "- DropBlock\n",
    "- Zone out\n",
    "- Stochastic weight averaging\n",
    "- Sharpness aware minimization\n",
    "- Surface loss\n",
    "- Partial convolution\n",
    "- Group normalization\n",
    "- Swish activation\n",
    "- Adabound\n",
    "- Equibatch\n",
    "- CutMix\n",
    "- \n",
    "\n",
    "\n",
    "## Package Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm_notebook, tnrange\n",
    "import tensorflow as tf\n",
    "\n",
    "sess = tf.Session()\n",
    "from keras import backend as K\n",
    "K.set_session(sess)\n",
    "\n",
    "from time import sleep\n",
    "\n",
    "import keras\n",
    "from tensorflow.python.keras.layers import *\n",
    "from tensorflow.python.keras.layers import ELU\n",
    "from keras.losses import binary_crossentropy\n",
    "from tensorflow.python.ops import array_ops\n",
    "from tensorflow.python.keras.layers import Conv2D, Lambda, Dense, Multiply, Add\n",
    "from tensorflow.initializers import glorot_normal, lecun_normal\n",
    "from scipy.ndimage import median_filter\n",
    "from skimage.transform import resize\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from random import shuffle\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import os\n",
    "import random\n",
    "import itertools\n",
    "from tensorflow.contrib.framework import arg_scope\n",
    "from keras.regularizers import l1\n",
    "from tensorflow.layers import batch_normalization\n",
    "from tensorflow.python.util import deprecation as deprecation\n",
    "deprecation._PRINT_DEPRECATION_WARNINGS = False\n",
    "\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From /Users/jbrandt.terminal/Documents/GitHub/sentinel-tree-cover/src/layers/convgru.py:27: The name tf.nn.rnn_cell.RNNCell is deprecated. Please use tf.compat.v1.nn.rnn_cell.RNNCell instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%run ../src/layers/zoneout.py\n",
    "%run ../src/layers/adabound.py\n",
    "%run ../src/layers/convgru.py\n",
    "%run ../src/layers/dropblock.py\n",
    "%run ../src/layers/extra_layers.py\n",
    "%run ../src/layers/stochastic_weight_averaging.py\n",
    "%run ../src/preprocessing/indices.py\n",
    "%run ../src/preprocessing/slope.py\n",
    "#%run ../src/utils/metrics.py\n",
    "#%run ../src/utils/lovasz.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ZONE_OUT_PROB = 0.90\n",
    "ACTIVATION_FUNCTION = 'swish'\n",
    "\n",
    "INITIAL_LR = 1e-3\n",
    "DROPBLOCK_MAXSIZE = 5\n",
    "\n",
    "N_CONV_BLOCKS = 1\n",
    "FINAL_ALPHA = 0.33\n",
    "LABEL_SMOOTHING = 0.03\n",
    "\n",
    "L2_REG = 0.\n",
    "BATCH_SIZE = 32\n",
    "MAX_DROPBLOCK = 0.6\n",
    "\n",
    "FRESH_START = True\n",
    "best_val = 0.2\n",
    "\n",
    "START_EPOCH = 1\n",
    "END_EPOCH = 100\n",
    "\n",
    "n_bands = 17\n",
    "initial_flt = 32\n",
    "mid_flt = 32 * 2\n",
    "high_flt = 32 * 2 * 2\n",
    "\n",
    "temporal_model = True\n",
    "input_size = 28\n",
    "output_size = 14"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom layer definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility blocks (Batch norm, cSSE, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sse_block(prevlayer, prefix):\n",
    "    '''Spatial excitation and channel squeeze layer.\n",
    "       Calculates a 1x1 convolution with sigmoid activation to create a \n",
    "       spatial map that is multiplied by the input layer\n",
    "\n",
    "         Parameters:\n",
    "          prevlayer (tf.Variable): input layer\n",
    "          prefix (str): prefix for tensorflow scope\n",
    "\n",
    "         Returns:\n",
    "          x (tf.Variable): output of the sse_block\n",
    "    '''\n",
    "    conv = Conv2D(1, (1, 1), padding=\"same\", kernel_initializer=tf.keras.initializers.he_normal(),\n",
    "                  activation='sigmoid', strides=(1, 1),\n",
    "                  name=prefix + \"_conv\")(prevlayer)\n",
    "    conv = Multiply(name=prefix + \"_mul\")([prevlayer, conv])\n",
    "    return conv\n",
    "\n",
    "\n",
    "class ReflectionPadding2D(Layer):\n",
    "    '''Adapted from https://github.com/mronta/CycleGAN-in-Keras/blob/master/reflection_padding.py\n",
    "       This is used instead of zero padding where possible to reduce boundary artifacts\n",
    "    '''\n",
    "    def __init__(self, padding=(1, 1), **kwargs):\n",
    "        self.padding = tuple(padding)\n",
    "        self.input_spec = [InputSpec(ndim=4)]\n",
    "        super(ReflectionPadding2D, self).__init__(**kwargs)\n",
    "\n",
    "    def compute_output_shape(self, s):\n",
    "        \"\"\" If you are using \"channels_last\" configuration\"\"\"\n",
    "        return (s[0], s[1] + 2 * self.padding[0], s[2] + 2 * self.padding[1], s[3])\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        w_pad,h_pad = self.padding\n",
    "        return tf.pad(x, [[0,0], [h_pad,h_pad], [w_pad,w_pad], [0,0] ], 'REFLECT')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conv GRU Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gru_block(inp, length, size, flt, scope, train, normalize = True):\n",
    "    '''Bidirectional convolutional GRU block with \n",
    "       zoneout and CSSE blocks in each time step\n",
    "\n",
    "         Parameters:\n",
    "          inp (tf.Variable): (B, T, H, W, C) layer\n",
    "          length (tf.Variable): (B, T) layer denoting number of\n",
    "                                steps per sample\n",
    "          size (int): kernel size of convolution\n",
    "          flt (int): number of convolution filters\n",
    "          scope (str): tensorflow variable scope\n",
    "          train (tf.Bool): flag to differentiate between train/test ops\n",
    "          normalize (bool): whether to compute layer normalization\n",
    "\n",
    "         Returns:\n",
    "          gru (tf.Variable): (B, H, W, flt*2) bi-gru output\n",
    "          steps (tf.Variable): (B, T, H, W, flt*2) output of each step\n",
    "    '''\n",
    "    with tf.variable_scope(scope):\n",
    "        print(f\"GRU input shape {inp.shape}, zoneout: {ZONE_OUT_PROB}\")\n",
    "        \n",
    "        # normalize is internal group normalization within the reset gate\n",
    "        # sse is internal SSE block within the state cell\n",
    "\n",
    "        cell_fw = ConvGRUCell(shape = size, filters = flt,\n",
    "                           kernel = [3, 3], padding = 'VALID', \n",
    "                           normalize = normalize, sse = True)\n",
    "        cell_bw = ConvGRUCell(shape = size, filters = flt,\n",
    "                           kernel = [3, 3], padding = 'VALID',\n",
    "                           normalize = normalize, sse = True)\n",
    "        \n",
    "        cell_fw = ZoneoutWrapper(\n",
    "           cell_fw, zoneout_drop_prob = ZONE_OUT_PROB, is_training = train)\n",
    "        cell_bw = ZoneoutWrapper(\n",
    "            cell_bw, zoneout_drop_prob = ZONE_OUT_PROB, is_training = train)\n",
    "        steps, out = convGRU(inp, cell_fw, cell_bw, length)\n",
    "        gru = tf.concat(out, axis = -1)\n",
    "        steps = tf.concat(steps, axis = -1)\n",
    "        print(f\"GRU block output shape {gru.shape}\")\n",
    "    return gru, steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conv blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partial_conv(x, channels, kernel=3, stride=1, use_bias=False, padding='SAME', scope='conv_0'):\n",
    "    \"\"\"Implementation of https://arxiv.org/abs/1804.07723\n",
    "       Partial conv is used in place of \"SAME\" padding to reduce boundary artifacts\n",
    "    \"\"\"\n",
    "    with tf.variable_scope(scope):\n",
    "        if padding.lower() == 'SAME'.lower() :\n",
    "            with tf.variable_scope('mask'):\n",
    "                _, h, w, _ = x.get_shape().as_list()\n",
    "\n",
    "                slide_window = kernel * kernel\n",
    "                mask = tf.ones(shape=[1, h, w, 1])\n",
    "\n",
    "                update_mask = tf.layers.conv2d(mask, filters=1,\n",
    "                                               kernel_size=kernel,\n",
    "                                               kernel_initializer=tf.constant_initializer(1.0),\n",
    "                                               strides=stride, \n",
    "                                               padding=padding, \n",
    "                                               use_bias=False,\n",
    "                                               trainable=False)\n",
    "\n",
    "                mask_ratio = slide_window / (update_mask + 1e-8)\n",
    "                update_mask = tf.clip_by_value(update_mask, 0.0, 1.0)\n",
    "                mask_ratio = mask_ratio * update_mask\n",
    "\n",
    "            with tf.variable_scope('x'):\n",
    "                x = tf.layers.conv2d(x, filters=channels,\n",
    "                                     kernel_size=kernel, \n",
    "                                     kernel_initializer=tf.keras.initializers.he_normal(),\n",
    "                                     strides=stride,\n",
    "                                     padding=padding, \n",
    "                                     use_bias=False)\n",
    "                x = x * mask_ratio\n",
    "\n",
    "                if use_bias:\n",
    "                    bias = tf.get_variable(\"bias\", \n",
    "                                           [channels],\n",
    "                                           initializer=tf.constant_initializer(0.0))\n",
    "\n",
    "                    x = tf.nn.bias_add(x, bias)\n",
    "                    x = x * update_mask\n",
    "\n",
    "        else :\n",
    "            x = tf.layers.conv2d(x, filters=channels,\n",
    "                                 kernel_size=kernel, \n",
    "                                 kernel_initializer=tf.keras.initializers.he_normal(),\n",
    "                                 strides=stride,\n",
    "                                 padding=padding,\n",
    "                                 use_bias=use_bias)\n",
    "\n",
    "        return x\n",
    "\n",
    "def conv_swish_gn(inp, \n",
    "                 is_training, \n",
    "                 kernel_size,\n",
    "                 scope,\n",
    "                 filters, \n",
    "                 keep_rate,\n",
    "                 stride = (1, 1),\n",
    "                 activation = True,\n",
    "                 use_bias = False,\n",
    "                 norm = True,\n",
    "                 dropblock = True,\n",
    "                 csse = True,\n",
    "                 weight_decay = None,\n",
    "                 block_size = 5,\n",
    "                 padding = \"SAME\",\n",
    "                 partial = True):\n",
    "    '''2D convolution, group normalization, SWISH activation, drop block, SSE. \n",
    "       DropBlock performs best when applied last, according to original paper.\n",
    "       This is the core CONV block for this model.\n",
    "\n",
    "         Parameters:\n",
    "          inp (tf.Variable): input layer\n",
    "          is_training (str): flag to differentiate between train/test ops\n",
    "          kernel_size (int): size of convolution\n",
    "          scope (str): tensorflow variable scope\n",
    "          filters (int): number of filters for convolution\n",
    "          keep_rate (float): Keep rate for dropblock\n",
    "          stride (tuple): Conv2D stride parameter\n",
    "          activation (bool): Whether or not to apply Swish activation\n",
    "          use_bias (bool): whether to use bias. Should always be false\n",
    "          norm (bool): whether or not to apply group normalization\n",
    "          dropblock (bool): whether or not to apply dropblock\n",
    "          csse (bool): whether or not to apply SSE block\n",
    "          weight_decay (bool): not currently implemented\n",
    "          block_size (int): Block size for dropblock\n",
    "          padding (str): padding parameter for conv2d\n",
    "          partial (bool): Whether or not to use partial conv or Conv2D\n",
    "\n",
    "         Returns:\n",
    "          conv (tf.Variable): output of the block\n",
    "        \n",
    "         References:\n",
    "          http://papers.nips.cc/paper/8271-dropblock-a-regularization-\n",
    "              method-for-convolutional-networks.pdf\n",
    "          https://arxiv.org/abs/1702.03275\n",
    "          \n",
    "    '''\n",
    "    \n",
    "    gn_flag = \"Group Norm\" if norm else \"\"\n",
    "    activation_flag = \"RELU\" if activation else \"Linear\"\n",
    "    sse_flag = \"SSE\" if csse else \"No SSE\"\n",
    "    bias_flag = \"Bias\" if use_bias else \"NoBias\"\n",
    "    drop_flag = \"DropBlock\" if dropblock else \"NoDrop\"\n",
    "        \n",
    "    print(f\"{scope} Conv: Kernel: {kernel_size}, {gn_flag}, {activation_flag}, {sse_flag}, {drop_flag}\")\n",
    "\n",
    "    with tf.variable_scope(scope + \"_conv\"):\n",
    "        if not partial:\n",
    "            conv = Conv2D(filters = filters, \n",
    "                          kernel_size = (kernel_size, kernel_size), \n",
    "                          strides = stride,\n",
    "                          activation = None,\n",
    "                          padding = 'valid',\n",
    "                          use_bias = use_bias,\n",
    "                          kernel_initializer = tf.keras.initializers.he_normal()\n",
    "                         )(inp)\n",
    "        if partial:\n",
    "            conv = partial_conv(inp, filters,\n",
    "                                kernel=kernel_size, \n",
    "                                stride=1, \n",
    "                                use_bias=False,\n",
    "                                padding=padding, \n",
    "                                scope = scope)\n",
    "    if activation:\n",
    "        conv = tf.nn.swish(conv)\n",
    "    if norm:\n",
    "        conv = group_norm(x = conv, scope = scope, G = 8)\n",
    "    if csse:\n",
    "        conv = sse_block(conv, \"csse_\" + scope)\n",
    "    if dropblock: \n",
    "        with tf.variable_scope(scope + \"_drop\"):\n",
    "            drop_block = DropBlock2D(keep_prob=keep_rate, block_size= block_size)\n",
    "            conv = drop_block(conv, is_training)\n",
    "    return conv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model definition\n",
    "\n",
    "## Placeholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Scale of 0 disables regularizer.\n"
     ]
    }
   ],
   "source": [
    "reg = tf.contrib.layers.l2_regularizer(0.)\n",
    "temporal_model = True\n",
    "input_size = 28\n",
    "n_bands = 17\n",
    "output_size = 14\n",
    "\n",
    "if temporal_model:\n",
    "    inp = tf.placeholder(tf.float32, shape=(None, 13, input_size, input_size, n_bands))\n",
    "    length = tf.placeholder_with_default(np.full((1,), 12), shape = (None,))\n",
    "else:\n",
    "    inp = tf.placeholder(tf.float32, shape=(None, input_size, input_size, n_bands))\n",
    "    \n",
    "labels = tf.placeholder(tf.float32, shape=(None, output_size, output_size))#, 1))\n",
    "keep_rate = tf.placeholder_with_default(1.0, ()) # For DropBlock\n",
    "is_training = tf.placeholder_with_default(False, (), 'is_training') # For DropBlock\n",
    "alpha = tf.placeholder(tf.float32, shape = ()) # For loss scheduling\n",
    "ft_lr = tf.placeholder_with_default(0.001, shape = ()) # For loss scheduling\n",
    "loss_weight = tf.placeholder_with_default(1.0, shape = ())\n",
    "beta_ = tf.placeholder_with_default(0.0, shape = ()) # For loss scheduling, not currently implemented"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "The model uses a UNet architecture where the encoder extracts increasingly abstract features and the decoder upsamples the features to the target resolution.\n",
    "\n",
    "The encoder consists of three blocks:\n",
    "\n",
    "- GRU: A bidirectional convolutional GRU with channel squeeze and spatial excitation, and group normalization, extracts 3x3 features from the multitemporal imagery\n",
    "- Conv1: A MaxPool-conv-swish-groupNorm-csse layer takes the output of the GRU (size 28) and reduces to size 12\n",
    "- Conv2: The output of the MaxPool-conv-swish-csse-DropBlock is a 4x4x128 encoded feature map\n",
    "\n",
    "The decoder consists of two blocks:\n",
    "\n",
    "- Upconv1: upsample-conv-swish-csse-concat-conv-swish\n",
    "- Upconv2: upsample-conv-swish-csse-concat-conv-swish\n",
    "- Output sigmoid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GRU input shape (?, 12, 28, 28, 17), zoneout: 0.9\n",
      "WARNING:tensorflow:From /Users/jbrandt.terminal/opt/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n",
      "(3, 3, 33, 32)\n",
      "(3, 3, 33, 32)\n",
      "GRU block output shape (?, 28, 28, 32)\n",
      "WARNING:tensorflow:From /Users/jbrandt.terminal/opt/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/jbrandt.terminal/opt/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "conv_median Conv: Kernel: 3, Group Norm, RELU, SSE, DropBlock\n",
      "Median conv: (?, 28, 28, 32)\n",
      "conv_concat Conv: Kernel: 3, Group Norm, RELU, SSE, DropBlock\n",
      "Concat: (?, 28, 28, 32)\n",
      "conv1 Conv: Kernel: 3, Group Norm, RELU, SSE, DropBlock\n",
      "Conv1: (?, 12, 12, 64)\n",
      "conv2 Conv: Kernel: 3, Group Norm, RELU, SSE, DropBlock\n",
      "Encoded (?, 4, 4, 128)\n",
      "up2 Conv: Kernel: 3, Group Norm, RELU, SSE, DropBlock\n",
      "(?, 8, 8, 64)\n",
      "up2_out Conv: Kernel: 3, Group Norm, RELU, SSE, DropBlock\n",
      "up3 Conv: Kernel: 3, Group Norm, RELU, SSE, DropBlock\n",
      "(?, 16, 16, 32)\n",
      "(?, 16, 16, 32)\n",
      "out Conv: Kernel: 3, Group Norm, RELU, SSE, NoDrop\n",
      "The output is (?, 8, 8, 64), with a receptive field of 1\n",
      "The output, sigmoid is (?, 14, 14, 1), with a receptive field of 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\nup4 = conv_swish_gn(inp = up3, is_training = is_training, stride = (1, 1),\\n                    kernel_size = 3, scope = \\'outregressor\\', filters = mid_flt, \\n                    keep_rate  = keep_rate, activation = True, use_bias = False, norm = True,\\n                    csse = True, dropblock =True, weight_decay = None, padding = \"SAME\")\\n#up4 = ReflectionPadding2D((1, 1,))(up4)\\nup5 = conv_swish_gn(inp = up4, is_training = is_training, stride = (1, 1),\\n                    kernel_size = 3, scope = \\'outregressor2\\', filters = mid_flt, \\n                    keep_rate  = keep_rate, activation = True, use_bias = False, norm = True,\\n                    csse = True, dropblock = False, weight_decay = None, padding = \"VALID\")\\n\\nregression = Conv2D(filters = 1,\\n            kernel_size = (1, 1),\\n            padding = \\'valid\\',\\n            activation = \\'linear\\',\\n            #bias_initializer = init,\\n           )(up5)\\n\\noutput = regression + fm\\noutput = tf.clip_by_value(output, 0, 1)\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# master modmel is 32, 64, 96, 230k paramms\n",
    "initial_flt = 32\n",
    "mid_flt = 32 * 2\n",
    "high_flt = 32 * 2 * 2\n",
    "INPUT_SIZE = 28\n",
    "SIZE_X = 28\n",
    "\n",
    "#inp = ReflectionPadding5D((1, 1))(inp)\n",
    "gru_input = inp[:, :12, ...]\n",
    "gru, steps = gru_block(inp = gru_input, length = length,\n",
    "                            size = [INPUT_SIZE, SIZE_X, ], # + 2 here for refleclt pad\n",
    "                            flt = initial_flt // 2,\n",
    "                            scope = 'down_16',\n",
    "                            train = is_training)\n",
    "with tf.variable_scope(\"gru_drop\"):\n",
    "    drop_block = DropBlock2D(keep_prob=keep_rate, block_size=4)\n",
    "    gru = drop_block(gru, is_training)\n",
    "    \n",
    "# Median conv\n",
    "median_input = inp[:, -1, ...]\n",
    "median_conv = conv_swish_gn(inp = median_input, is_training = is_training, stride = (1, 1),\n",
    "            kernel_size = 3, scope = 'conv_median', filters = initial_flt, \n",
    "            keep_rate = keep_rate, activation = True, use_bias = False, norm = True,\n",
    "            csse = True, dropblock = True, weight_decay = None)\n",
    "\n",
    "print(f\"Median conv: {median_conv.shape}\")\n",
    "\n",
    "concat1 = tf.concat([gru, median_conv], axis = -1)\n",
    "concat = conv_swish_gn(inp = concat1, is_training = is_training, stride = (1, 1),\n",
    "            kernel_size = 3, scope = 'conv_concat', filters = initial_flt,\n",
    "            keep_rate = keep_rate, activation = True, use_bias = False, norm = True,\n",
    "            csse = True, dropblock = True, weight_decay = None, padding = \"SAME\")\n",
    "print(f\"Concat: {concat.shape}\")\n",
    "\n",
    "    \n",
    "# MaxPool-conv-swish-GroupNorm-csse\n",
    "pool1 = MaxPool2D()(concat)\n",
    "conv1 = conv_swish_gn(inp = pool1, is_training = is_training, stride = (1, 1),\n",
    "            kernel_size = 3, scope = 'conv1', filters = mid_flt,\n",
    "            keep_rate = keep_rate, activation = True, use_bias = False, norm = True, padding = \"VALID\",\n",
    "            csse = True, dropblock = True, weight_decay = None)\n",
    "print(f\"Conv1: {conv1.shape}\")\n",
    "\n",
    "# MaxPool-conv-swish-csse-DropBlock\n",
    "pool2 = MaxPool2D()(conv1)\n",
    "conv2 = conv_swish_gn(inp = pool2, is_training = is_training, stride = (1, 1),\n",
    "            kernel_size = 3, scope = 'conv2', filters = high_flt, \n",
    "            keep_rate = keep_rate, activation = True, use_bias = False, norm = True,\n",
    "            csse = True, dropblock = True, weight_decay = None, block_size = 4, padding = \"VALID\")\n",
    "print(\"Encoded\", conv2.shape)\n",
    "\n",
    "# Decoder 4 - 8, upsample-conv-swish-csse-concat-conv-swish\n",
    "up2 = tf.keras.layers.UpSampling2D((2, 2), interpolation = 'nearest')(conv2)\n",
    "#up2 = ReflectionPadding2D((1, 1,))(up2)\n",
    "up2 = conv_swish_gn(inp = up2, is_training = is_training, stride = (1, 1),\n",
    "                    kernel_size = 3, scope = 'up2', filters = mid_flt, \n",
    "                    keep_rate = keep_rate, activation = True, use_bias = False, norm = True,\n",
    "                    csse = True, dropblock = True, weight_decay = None)\n",
    "conv1_crop = Cropping2D(2)(conv1)\n",
    "print(conv1_crop.shape)\n",
    "up2 = tf.concat([up2, conv1_crop], -1)\n",
    "#up2 = ReflectionPadding2D((1, 1,))(up2)\n",
    "up2 = conv_swish_gn(inp = up2, is_training = is_training, stride = (1, 1),\n",
    "                    kernel_size = 3, scope = 'up2_out', filters = mid_flt, \n",
    "                    keep_rate =  keep_rate, activation = True, use_bias = False, norm = True,\n",
    "                    csse = True, dropblock = True, weight_decay = None)\n",
    "\n",
    "# Decoder 8 - 14 upsample-conv-swish-csse-concat-conv-swish\n",
    "up3 = tf.keras.layers.UpSampling2D((2, 2), interpolation = 'nearest')(up2)\n",
    "#up3 = ReflectionPadding2D((1, 1,))(up3)\n",
    "up3 = conv_swish_gn(inp = up3, is_training = is_training, stride = (1, 1),\n",
    "                    kernel_size = 3, scope = 'up3', filters = initial_flt, \n",
    "                    keep_rate = keep_rate, activation = True, use_bias = False, norm = True,\n",
    "                    csse = True, dropblock = True, weight_decay = None)\n",
    "gru_crop = Cropping2D(6)(concat)\n",
    "print(up3.shape)\n",
    "print(gru_crop.shape)\n",
    "up3 = tf.concat([up3, gru_crop], -1)\n",
    "\n",
    "up3out = conv_swish_gn(inp = up3, is_training = is_training, stride = (1, 1),\n",
    "                    kernel_size = 3, scope = 'out', filters = initial_flt, \n",
    "                    keep_rate  = keep_rate, activation = True, use_bias = False, norm = True,\n",
    "                    csse = True, dropblock = False, weight_decay = None, padding = \"VALID\")\n",
    "\n",
    "\n",
    "#print(\"Initializing last sigmoid bias with -2.94 constant\")\n",
    "init = tf.constant_initializer([-np.log(0.7/0.3)]) # For focal loss\n",
    "print(f\"The output is {up2.shape}, with a receptive field of {1}\")\n",
    "fm = Conv2D(filters = 1,\n",
    "            kernel_size = (1, 1),\n",
    "            padding = 'valid',\n",
    "            activation = 'sigmoid',\n",
    "            bias_initializer = init,\n",
    "           )(up3out) # For focal loss\n",
    "#fm = Cropping2D(1)(fm)\n",
    "\n",
    "print(f\"The output, sigmoid is {fm.shape}, with a receptive field of {1}\")\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "up4 = conv_swish_gn(inp = up3, is_training = is_training, stride = (1, 1),\n",
    "                    kernel_size = 3, scope = 'outregressor', filters = mid_flt, \n",
    "                    keep_rate  = keep_rate, activation = True, use_bias = False, norm = True,\n",
    "                    csse = True, dropblock =True, weight_decay = None, padding = \"SAME\")\n",
    "#up4 = ReflectionPadding2D((1, 1,))(up4)\n",
    "up5 = conv_swish_gn(inp = up4, is_training = is_training, stride = (1, 1),\n",
    "                    kernel_size = 3, scope = 'outregressor2', filters = mid_flt, \n",
    "                    keep_rate  = keep_rate, activation = True, use_bias = False, norm = True,\n",
    "                    csse = True, dropblock = False, weight_decay = None, padding = \"VALID\")\n",
    "\n",
    "regression = Conv2D(filters = 1,\n",
    "            kernel_size = (1, 1),\n",
    "            padding = 'valid',\n",
    "            activation = 'linear',\n",
    "            #bias_initializer = init,\n",
    "           )(up5)\n",
    "\n",
    "output = regression + fm\n",
    "output = tf.clip_by_value(output, 0, 1)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfinetune_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, \"csse_out\") +                 tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, \"out\")+                 tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES,\"conv2d_13\") +                 tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, \"up3\") +                 tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, \"up3_drop\") +                 tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, \"csse_up3\") +                 tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, \"up2_out\") +                 tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, \"up2_out_drop\") +                 tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, \"csse_up2_out\") +                 tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES,\"conv2d_15\") +                 tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, \"outregressor\") +                 tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, \"csse_outregressor\")# +                 #tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, \"up2\") +                 #tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, \"up2_drop\") +                 #tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, \"csse_up2\") +                 #tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, \"conv2\") +                 #tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, \"conv2_drop\") +                 #tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, \"csse_conv2\") +                 #tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, \"conv1\") +                 #tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, \"conv1_drop\") +                 #tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, \"csse_conv1\") +                 #tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, \"conv_concat\") +                 #tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, \"conv_concat_drop\") +                 #tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, \"csse_conv_concat\")\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finetune_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES,\"conv2d_15\") + \\\n",
    "                tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES,\"conv2d_17\") + \\\n",
    "                tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, \"outregressor\") + \\\n",
    "                tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, \"csse_outregressor\") + \\\n",
    "                tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, \"outregressor_drop\") + \\\n",
    "                tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, \"outregressor2\") + \\\n",
    "                tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, \"csse_outregressor2\") + \\\n",
    "                tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES,\"conv2d_13\") + \\\n",
    "                tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, \"csse_out\") + \\\n",
    "                tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, \"out\") + \\\n",
    "                tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, \"up3\") + \\\n",
    "                tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, \"up3_drop\") + \\\n",
    "                tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, \"csse_up3\") + \\\n",
    "                tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, \"up2_out\") + \\\n",
    "                tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, \"up2_out_drop\") + \\\n",
    "                tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, \"csse_up2_out\") + \\\n",
    "                tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, \"up2\") + \\\n",
    "                tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, \"up2_drop\") + \\\n",
    "                tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, \"csse_up2\")# + \\\n",
    "\n",
    "new_varsinit = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES,\"conv2d_15\") + \\\n",
    "                tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES,\"conv2d_17\") + \\\n",
    "                tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, \"outregressor\") + \\\n",
    "                tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, \"csse_outregressor\") + \\\n",
    "                tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, \"outregressor_drop\") + \\\n",
    "                tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, \"outregressor2\") + \\\n",
    "                tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, \"csse_outregressor2\")\n",
    "#finetune_vars = new_varsinit\n",
    "\"\"\"\n",
    "finetune_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, \"csse_out\") + \\\n",
    "                tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, \"out\")+ \\\n",
    "                tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES,\"conv2d_13\") + \\\n",
    "                tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, \"up3\") + \\\n",
    "                tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, \"up3_drop\") + \\\n",
    "                tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, \"csse_up3\") + \\\n",
    "                tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, \"up2_out\") + \\\n",
    "                tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, \"up2_out_drop\") + \\\n",
    "                tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, \"csse_up2_out\") + \\\n",
    "                tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES,\"conv2d_15\") + \\\n",
    "                tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, \"outregressor\") + \\\n",
    "                tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, \"csse_outregressor\")# + \\\n",
    "                #tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, \"up2\") + \\\n",
    "                #tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, \"up2_drop\") + \\\n",
    "                #tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, \"csse_up2\") + \\\n",
    "                #tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, \"conv2\") + \\\n",
    "                #tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, \"conv2_drop\") + \\\n",
    "                #tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, \"csse_conv2\") + \\\n",
    "                #tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, \"conv1\") + \\\n",
    "                #tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, \"conv1_drop\") + \\\n",
    "                #tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, \"csse_conv1\") + \\\n",
    "                #tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, \"conv_concat\") + \\\n",
    "                #tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, \"conv_concat_drop\") + \\\n",
    "                #tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, \"csse_conv_concat\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model has 329929 parameters\n"
     ]
    }
   ],
   "source": [
    "total_parameters = 0\n",
    "for variable in tf.trainable_variables():\n",
    "    shape = variable.get_shape()\n",
    "    variable_parameters = 1\n",
    "    for dim in shape:\n",
    "        variable_parameters *= dim.value\n",
    "    total_parameters += variable_parameters\n",
    "print(f\"This model has {total_parameters} parameters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.losses import binary_crossentropy\n",
    "import math\n",
    "from scipy.ndimage import distance_transform_edt as distance\n",
    "\n",
    "def weighted_bce_loss(y_true, y_pred, weight, mask = True, smooth = 0.03):\n",
    "    '''Calculates the weighted binary cross entropy loss between y_true and\n",
    "       y_pred with optional masking and smoothing for regularization\n",
    "       \n",
    "       For smoothing, we want to weight false positives as less important than\n",
    "       false negatives, so we smooth false negatives 2x as much. \n",
    "    \n",
    "         Parameters:\n",
    "          y_true (arr):\n",
    "          y_pred (arr):\n",
    "          weight (float):\n",
    "          mask (arr): DEPRECATED\n",
    "          smooth (float):\n",
    "\n",
    "         Returns:\n",
    "          loss (float):\n",
    "    '''\n",
    "    epsilon = 1e-7\n",
    "    y_pred = K.clip(y_pred, epsilon, 1. - epsilon)\n",
    "    y_true = K.clip(y_true, smooth, 1. - smooth)\n",
    "    logit_y_pred = K.log(y_pred / (1. - y_pred))\n",
    "    loss = tf.nn.weighted_cross_entropy_with_logits(\n",
    "        y_true,\n",
    "        logit_y_pred,\n",
    "        weight,\n",
    "    )\n",
    "\n",
    "    return loss\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def calc_dist_map(seg):\n",
    "    \n",
    "    \"\"\"\n",
    "    This is a modified version of surface loss to reduce\n",
    "    the loss importance of samples at the boundary. THe original\n",
    "    paper specifies a boundary loss of 0, but the low-resolution of\n",
    "    Sentinel data requires some amount of boundary importance, and\n",
    "    this function works well to accomplish that task\n",
    "    \"\"\"\n",
    "\n",
    "    res = np.zeros_like(seg)\n",
    "    posmask = seg.astype(np.bool)\n",
    "\n",
    "    mults = np.ones_like(seg)\n",
    "    ones = np.ones_like(seg)\n",
    "    for x in range(1, res.shape[0] -1 ):\n",
    "        for y in range(1, res.shape[0] - 1):\n",
    "            # If > 1 px distance, double the weight of the positive\n",
    "            # If == 1 px, half the weight of the negative\n",
    "            # This is important because the calc_mask fn\n",
    "            # leaves borders with 0 weight otherwise\n",
    "            if seg[x, y] == 1:\n",
    "                l = seg[x - 1, y]\n",
    "                r = seg[x + 1, y]\n",
    "                u = seg[x, y + 1]\n",
    "                d = seg[x, y - 1]\n",
    "                lu = seg[x - 1, y + 1]\n",
    "                ru = seg[x + 1, y + 1]\n",
    "                rd = seg[x + 1, y - 1]\n",
    "                ld = seg[x -1, y - 1]\n",
    "                \n",
    "                sums = (l + r + u + d)\n",
    "                sums2 = (l + r + u + d + lu + ru +rd + ld)\n",
    "                if sums >= 2:\n",
    "                    mults[x, y] = 2\n",
    "                if sums2 <= 1:\n",
    "                    ones[x - 1, y] = 0.5\n",
    "                    ones[x + 1, y] = 0.5\n",
    "                    ones[x, y + 1] = 0.5\n",
    "                    ones[x, y - 1] = 0.5\n",
    "                    ones[x - 1, y + 1] = 0.5\n",
    "                    ones[x + 1, y + 1] = 0.5\n",
    "                    ones[x + 1, y - 1] = 0.5\n",
    "                    ones[x -1, y - 1] = 0.5\n",
    "\n",
    "    if posmask.any():\n",
    "        negmask = ~posmask\n",
    "        res = distance(negmask) * negmask - (distance(posmask) - 1) * posmask\n",
    "        # When % = 1, 0 -> 1.75\n",
    "        # When % = 100, 0 -> 0\n",
    "        res = np.round(res, 0)\n",
    "        res[np.where(np.isclose(res, -.41421356, rtol = 1e-2))] = -1\n",
    "        res[np.where(res == -1)] = -1 * mults[np.where(res == -1)]\n",
    "        res[np.where(res == 0)] = -1  * mults[np.where(res == 0)]\n",
    "        # When % = 1, 1 -> 0\n",
    "        # When % = 100, 1 -> 1.75\n",
    "        res[np.where(res == 1)] = 1 * ones[np.where(res == 1)]\n",
    "        res[np.where(res == 1)] *= 0.67\n",
    "        \n",
    "    # Empirically capping the loss at -3 to 3 is better\n",
    "    res[np.where(res < -3)] = -3\n",
    "    res[np.where(res > 3)] = 3\n",
    "    if np.sum(seg) == 196:\n",
    "        res = np.ones_like(seg)\n",
    "        res *= -1\n",
    "    if np.sum(seg) == 0:\n",
    "        res = np.ones_like(seg)\n",
    "    return res\n",
    "\n",
    "\n",
    "def calc_dist_map_batch(y_true):\n",
    "    '''Applies calc_dist_map to each sample in an input batch\n",
    "    \n",
    "         Parameters:\n",
    "          y_true (arr):\n",
    "          \n",
    "         Returns:\n",
    "          loss (arr):\n",
    "    '''\n",
    "    y_true_numpy = y_true.numpy()\n",
    "    return np.array([calc_dist_map(y)\n",
    "                     for y in y_true_numpy]).astype(np.float32)\n",
    "\n",
    "\n",
    "def surface_loss(y_true, y_pred):\n",
    "    '''Calculates the mean surface loss for the input batch\n",
    "       by multiplying the distance map by y_pred\n",
    "    \n",
    "         Parameters:\n",
    "          y_true (arr):\n",
    "          y_pred (arr):\n",
    "          \n",
    "         Returns:\n",
    "          loss (arr):\n",
    "        \n",
    "         References:\n",
    "          https://arxiv.org/abs/1812.07032\n",
    "    '''\n",
    "    y_true_dist_map = tf.py_function(func=calc_dist_map_batch,\n",
    "                                     inp=[y_true],\n",
    "                                     Tout=tf.float32)\n",
    "    y_true_dist_map = tf.stack(y_true_dist_map, axis = 0)\n",
    "    multipled = y_pred * y_true_dist_map\n",
    "    loss = tf.reduce_mean(multipled, axis = (1, 2, 3))\n",
    "    return loss\n",
    "\n",
    "\n",
    "def bce_surface_loss(y_true, y_pred, alpha, weight, beta):\n",
    "    \n",
    "    \"\"\" Combines surface loss and binary cross entropy with a \n",
    "    alpha weighting factor. Beta is currently deprecated.\"\"\"\n",
    "    \n",
    "    bce = weighted_bce_loss(y_true = y_true, \n",
    "                             y_pred = y_pred, \n",
    "                             weight = weight,\n",
    "                             smooth = 0.03)\n",
    "\n",
    "    bce = tf.reduce_mean(bce, axis = (1, 2, 3))\n",
    "    surface = surface_loss(tf.cast(tf.math.greater(y_true, 0.10), tf.float32), y_pred)\n",
    "    surface = tf.reduce_mean(surface)\n",
    "\n",
    "    bce = tf.reduce_mean(bce)\n",
    "    bce = (1 - alpha) * bce\n",
    "    surface_portion = alpha * surface\n",
    "    result = bce + surface_portion\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.0931471805599452"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.2 + (2 * 0.2) - np.log(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logcosh(y_true, y_pred):\n",
    "  \n",
    "    y_pred = ops.convert_to_tensor(y_pred)\n",
    "    #y_pred = tf.clip_by_value(y_pred, 0, 1)\n",
    "    #y_pred = logit(y_pred)\n",
    "    y_true = math_ops.cast(y_true, y_pred.dtype)\n",
    "    \n",
    "    #def _logcosh(x):\n",
    "    # s always has real part >= 0\n",
    "    #    s = np.sign(x) * x\n",
    "    #    p = np.exp(-2 * s)\n",
    "    #    return s + np.log1p(p) - np.log(2)\n",
    "\n",
    "    def _logcosh(x):\n",
    "        return x + tf.nn.softplus(-2. * x) - math_ops.log(2.)\n",
    "    return tf.reduce_mean(tf.squared_difference(y_true, y_pred))#tf.losses.mean_squared_error(y_true, y_pred)\n",
    "\n",
    "    #return tf.reduce_mean(_logcosh(y_pred - y_true))#, axis = (1, 2, 3))\n",
    "\n",
    "def logit(x):\n",
    "    \"\"\" Computes the logit function, i.e. the logistic sigmoid inverse. \"\"\"\n",
    "    return - tf.log(1. / x - 1.)\n",
    "\n",
    "def nplogit(x):\n",
    "    \"\"\" Computes the logit function, i.e. the logistic sigmoid inverse. \"\"\"\n",
    "    return - np.log(1. / x - 1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting model with: \n",
      " 0.9 zone out \n",
      " 0.0 l2 \n",
      "0.001 initial LR \n",
      " 329929 parameters\n"
     ]
    }
   ],
   "source": [
    "def grad_norm(gradients):\n",
    "    norm = tf.compat.v1.norm(\n",
    "        tf.stack([\n",
    "            tf.compat.v1.norm(grad) for grad in gradients if grad is not None\n",
    "        ])\n",
    "    )\n",
    "    return norm\n",
    "\n",
    "FRESH_START = True\n",
    "print(f\"Starting model with: \\n {ZONE_OUT_PROB} zone out \\n {L2_REG} l2 \\n\"\n",
    "      f\"{INITIAL_LR} initial LR \\n {total_parameters} parameters\")  \n",
    "\n",
    "if FRESH_START:\n",
    "    # We use the Adabound optimizer\n",
    "    optimizer = AdaBoundOptimizer(INITIAL_LR, ft_lr)\n",
    "    #train_loss1 = logcosh(tf.reshape(labels, (-1, 14, 14, 1)), output) \n",
    "    \n",
    "    train_loss2 = bce_surface_loss(tf.reshape(labels, (-1, 14, 14, 1)), fm,\n",
    "                                  weight = loss_weight, \n",
    "                             alpha = alpha, beta = beta_)\n",
    "\n",
    "    train_loss = train_loss2# + train_loss2\n",
    "    \n",
    "    # If there is any L2 regularization, add it. Current model does not use\n",
    "    l2_loss = tf.losses.get_regularization_loss()\n",
    "    if len(tf.losses.get_regularization_losses()) > 0:\n",
    "        train_loss = train_loss + l2_loss\n",
    "        \n",
    "    # If necessary to switch to SGD at any point, make that optimizer here\n",
    "    #ft_optimizer = tf.train.MomentumOptimizer(ft_lr, momentum = 0.8, use_nesterov = True)\n",
    "    \n",
    "    \n",
    "    test_loss = bce_surface_loss(tf.reshape(labels, (-1, 14, 14, 1)),\n",
    "                            fm, weight = loss_weight, \n",
    "                            alpha = alpha, beta = beta_)\n",
    "    update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "    \n",
    "    with tf.control_dependencies(update_ops):\n",
    "        train_op = optimizer.minimize(train_loss, var_list = finetune_vars)   \n",
    "        #ft_op = ft_optimizer.minimize(train_loss)\n",
    "    \n",
    "    # The following code blocks are for sharpness aware minimization\n",
    "    # Adapted from https://github.com/sayakpaul/Sharpness-Aware-Minimization-TensorFlow\n",
    "    # For tensorflow 1.15\n",
    "    trainable_params = tf.trainable_variables()\n",
    "    gradients = optimizer.compute_gradients(loss=train_loss, var_list=None)\n",
    "    gradient_norm = grad_norm(gradients)\n",
    "    scale = 0.05 / (gradient_norm + 1e-12)\n",
    "    e_ws = []\n",
    "    for (grad, param) in gradients:\n",
    "        e_w = grad * scale\n",
    "        param.assign_add(e_w)\n",
    "        e_ws.append(e_w)\n",
    "\n",
    "    sam_gradients = optimizer.compute_gradients(loss=train_loss, var_list=None)\n",
    "    for (param, e_w) in zip(trainable_params, e_ws):\n",
    "        param.assign_sub(e_w)\n",
    "    train_step = optimizer.apply_gradients(sam_gradients)\n",
    "    \n",
    "    # Create a saver to save the model each epoch\n",
    "    init_op = tf.global_variables_initializer()\n",
    "    sess.run(init_op)\n",
    "    all_vars = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES)\n",
    "    all_vars = [x for x in all_vars if 'outregressor' not in x.name]\n",
    "    all_vars = [x for x in all_vars if 'conv2d_15' not in x.name]\n",
    "    all_vars = [x for x in all_vars if 'conv2d_17' not in x.name]\n",
    "    all_vars = [x for x in all_vars if 'outregressor2' not in x.name]\n",
    "    saver = tf.train.Saver(max_to_keep = 150, var_list = all_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting anew\n",
      "INFO:tensorflow:Restoring parameters from ../models/75-composite-masterfeb9/model\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nupdate_weights = [tf.assign(new, old) for (new, old) in \\n   zip(tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, \"outregressor\"), \\n                 tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, \"out\"))]\\n\\nsess.run(update_weights)\\n\\nupdate_weights = [tf.assign(new, old) for (new, old) in \\n   zip(tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, \"csse_outregressor\"), \\n                 tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, \"csse_out\"))]\\n\\nsess.run(update_weights)\\n\\nnewvars = [x for x in tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES,\"conv2d_15\") if \\'kernel\\' in x.name]\\noldvars = [x for x in tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES,\"conv2d_13\") if \\'kernel\\' in x.name]\\n\\n\\nupdate_weights = [tf.assign(new, old) for (new, old) in \\n   zip(newvars, oldvars)]\\n\\n\\n\\nsess.run(update_weights)\\nsess.run(tf.assign(newvars[0], tf.math.multiply(newvars[0], 0.2)))\\n'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FRESH_START = False\n",
    "model_path  = \"../models/75-composite-masterfeb9/\"\n",
    "saver = tf.train.Saver(max_to_keep = 150, var_list = all_vars)\n",
    "if not os.path.exists(model_path):\n",
    "    os.makedirs(model_path)\n",
    "if os.path.isfile(f\"{model_path}metrics.npy\"):\n",
    "    metrics = np.load(f\"{model_path}metrics.npy\")\n",
    "    print(f\"Loading {model_path}metrics.npy\")\n",
    "else:\n",
    "    print(\"Starting anew\")\n",
    "    metrics = np.zeros((6, 300))\n",
    "\n",
    "if not FRESH_START:\n",
    "    path = model_path\n",
    "    saver.restore(sess, tf.train.latest_checkpoint(path))\n",
    "    \n",
    "#newvars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES,\"conv2d_15\") + \\\n",
    "#tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, \"outregressor\") + \\\n",
    "#tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, \"csse_outregressor\")# + \\\n",
    "#finetune_vars\n",
    "sess.run(tf.variables_initializer(new_varsinit))\n",
    "\n",
    "\"\"\"\n",
    "update_weights = [tf.assign(new, old) for (new, old) in \n",
    "   zip(tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, \"outregressor\"), \n",
    "                 tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, \"out\"))]\n",
    "\n",
    "sess.run(update_weights)\n",
    "\n",
    "update_weights = [tf.assign(new, old) for (new, old) in \n",
    "   zip(tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, \"csse_outregressor\"), \n",
    "                 tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, \"csse_out\"))]\n",
    "\n",
    "sess.run(update_weights)\n",
    "\n",
    "newvars = [x for x in tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES,\"conv2d_15\") if 'kernel' in x.name]\n",
    "oldvars = [x for x in tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES,\"conv2d_13\") if 'kernel' in x.name]\n",
    "\n",
    "\n",
    "update_weights = [tf.assign(new, old) for (new, old) in \n",
    "   zip(newvars, oldvars)]\n",
    "\n",
    "\n",
    "\n",
    "sess.run(update_weights)\n",
    "sess.run(tf.assign(newvars[0], tf.math.multiply(newvars[0], 0.2)))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nft_optimizer = tf.train.MomentumOptimizer(ft_lr, momentum = 0.8, use_nesterov = True)\\ntrain_loss = bce_surface_loss(tf.reshape(labels, (-1, 14, 14, 1)), \\n                             fm, weight = loss_weight, \\n                             alpha = alpha, beta = beta_)\\nupdate_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\\n    \\nwith tf.control_dependencies(update_ops):\\n    #train_op = optimizer.minimize(train_loss)   \\n    ft_op = ft_optimizer.minimize(train_loss, var_list = finetune_vars)\\n\\ntrainable_params = tf.trainable_variables()\\ngradients = ft_optimizer.compute_gradients(loss=train_loss, var_list=None)\\ngradient_norm = grad_norm(gradients)\\nscale = 0.05 / (gradient_norm + 1e-12)\\ne_ws = []\\nfor (grad, param) in gradients:\\n    e_w = grad * scale\\n    param.assign_add(e_w)\\n    e_ws.append(e_w)\\n\\nsam_gradients = ft_optimizer.compute_gradients(loss=train_loss, var_list=None)\\nfor (param, e_w) in zip(trainable_params, e_ws):\\n    param.assign_sub(e_w)\\ntrain_step_ft = ft_optimizer.apply_gradients(sam_gradients)\\n\\ninitialize_uninitialized(sess)\\n'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def initialize_uninitialized(sess):\n",
    "    global_vars = tf.global_variables()\n",
    "    is_not_initialized = sess.run([tf.is_variable_initialized(var) for var in global_vars])\n",
    "    not_initialized_vars = [v for (v, f) in zip(global_vars, is_not_initialized) if not f]\n",
    "\n",
    "    if len(not_initialized_vars):\n",
    "        sess.run(tf.variables_initializer(not_initialized_vars))\n",
    "\n",
    "\"\"\"\n",
    "ft_optimizer = tf.train.MomentumOptimizer(ft_lr, momentum = 0.8, use_nesterov = True)\n",
    "train_loss = bce_surface_loss(tf.reshape(labels, (-1, 14, 14, 1)), \n",
    "                             fm, weight = loss_weight, \n",
    "                             alpha = alpha, beta = beta_)\n",
    "update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "    \n",
    "with tf.control_dependencies(update_ops):\n",
    "    #train_op = optimizer.minimize(train_loss)   \n",
    "    ft_op = ft_optimizer.minimize(train_loss, var_list = finetune_vars)\n",
    "\n",
    "trainable_params = tf.trainable_variables()\n",
    "gradients = ft_optimizer.compute_gradients(loss=train_loss, var_list=None)\n",
    "gradient_norm = grad_norm(gradients)\n",
    "scale = 0.05 / (gradient_norm + 1e-12)\n",
    "e_ws = []\n",
    "for (grad, param) in gradients:\n",
    "    e_w = grad * scale\n",
    "    param.assign_add(e_w)\n",
    "    e_ws.append(e_w)\n",
    "\n",
    "sam_gradients = ft_optimizer.compute_gradients(loss=train_loss, var_list=None)\n",
    "for (param, e_w) in zip(trainable_params, e_ws):\n",
    "    param.assign_sub(e_w)\n",
    "train_step_ft = ft_optimizer.apply_gradients(sam_gradients)\n",
    "\n",
    "initialize_uninitialized(sess)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementation of stochastic weight averaging\n",
    "\n",
    "\n",
    "        \n",
    "model_vars = tf.trainable_variables()\n",
    "swa = StochasticWeightAveraging()\n",
    "swa_op = swa.apply(var_list=model_vars)\n",
    "with tf.variable_scope('BackupVariables'):\n",
    "    # force tensorflow to keep theese new variables on the CPU ! \n",
    "    backup_vars = [tf.get_variable(var.op.name, dtype=var.value().dtype, trainable=False,\n",
    "                                   initializer=var.initialized_value())\n",
    "                   for var in model_vars]\n",
    "\n",
    "# operation to assign SWA weights to model\n",
    "swa_to_weights = tf.group(*(tf.assign(var, swa.average(var).read_value()) for var in model_vars))\n",
    "# operation to store model into backup variables\n",
    "save_weight_backups = tf.group(*(tf.assign(bck, var.read_value()) for var, bck in zip(model_vars, backup_vars)))\n",
    "# operation to get back values from backup variables to model\n",
    "restore_weight_backups = tf.group(*(tf.assign(var, bck.read_value()) for var, bck in zip(model_vars, backup_vars)))\n",
    "\n",
    "initialize_uninitialized(sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loading\n",
    "\n",
    "*  Load in CSV data from Collect Earth\n",
    "*  Reconstruct the X, Y grid for the Y data per sample\n",
    "*  Calculate remote sensing indices\n",
    "*  Stack X, Y, length data\n",
    "*  Apply median filter to DEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jbrandt.terminal/opt/anaconda3/envs/tf/lib/python3.7/site-packages/ipykernel_launcher.py:6: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  \n",
      "/Users/jbrandt.terminal/opt/anaconda3/envs/tf/lib/python3.7/site-packages/ipykernel_launcher.py:14: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  \n",
      "/Users/jbrandt.terminal/opt/anaconda3/envs/tf/lib/python3.7/site-packages/ipykernel_launcher.py:20: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n"
     ]
    }
   ],
   "source": [
    "\n",
    "outliers = [61, 141, 218, 296, 365, 386, 594, 679, 712, 976, 1909, 2015]\n",
    "#print([x for x in test_data['plotid'].iloc[outliers]])\n",
    "\n",
    "train_x = np.delete(train_x , outliers, 0)\n",
    "train_y = np.delete(train_y, outliers, 0)\n",
    "data = data.drop(outliers, 0)\n",
    "data = data.reset_index(drop = True)\n",
    "\n",
    "outliers = [102]\n",
    "#print([x for x in test_data['plotid'].iloc[outliers]])\n",
    "\n",
    "train_x = np.delete(train_x , outliers, 0)\n",
    "train_y = np.delete(train_y, outliers, 0)\n",
    "data = data.drop(outliers, 0)\n",
    "data = data.reset_index(drop = True)\n",
    "\n",
    "outliers = [7, 8, 9, 11, 17, 18, 13, 27, 40, 44, 56, 83, 142, ]\n",
    "train_x = np.delete(train_x , outliers, 0)\n",
    "train_y = np.delete(train_y, outliers, 0)\n",
    "data = data.drop(outliers, 0)\n",
    "data = data.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\noutliers = [61, 141, 218, 296, 365, 386, 594, 679, 712, 976, 1909, 2015]\\n#print([x for x in test_data['plotid'].iloc[outliers]])\\n\\ntrain_x = np.delete(train_x , outliers, 0)\\ntrain_y = np.delete(train_y, outliers, 0)\\ndata = data.drop(outliers, 0)\\ndata = data.reset_index(drop = True)\\n\\noutliers = [102]\\n#print([x for x in test_data['plotid'].iloc[outliers]])\\n\\ntrain_x = np.delete(train_x , outliers, 0)\\ntrain_y = np.delete(train_y, outliers, 0)\\ndata = data.drop(outliers, 0)\\ndata = data.reset_index(drop = True)\\n\\noutliers = [7, 8, 9, 11, 17, 18, 13, 27, 40, 44, 56, 83, 142, ]\\ntrain_x = np.delete(train_x , outliers, 0)\\ntrain_y = np.delete(train_y, outliers, 0)\\ndata = data.drop(outliers, 0)\\ndata = data.reset_index(drop = True)\\n\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import hickle as hkl\n",
    "\n",
    "train_x = hkl.load(\"../data/train/train_x.hkl\")\n",
    "train_y = hkl.load(\"../data/train/train_y.hkl\")\n",
    "data = pd.read_csv(\"../data/train/train_plot_ids.csv\")\n",
    "\n",
    "train_y = train_y / 255.\n",
    "if not isinstance(train_x.flat[0], np.floating):\n",
    "    assert np.max(train_x) > 1\n",
    "    train_x = train_x / 65535.\n",
    "\n",
    "# In our training data, index 11 specified the date of the imagery\n",
    "# Which lead to overfitting, so it is removed here\n",
    "train_x = np.delete(train_x, 11, -1)\n",
    "\"\"\"\n",
    "outliers = [61, 141, 218, 296, 365, 386, 594, 679, 712, 976, 1909, 2015]\n",
    "#print([x for x in test_data['plotid'].iloc[outliers]])\n",
    "\n",
    "train_x = np.delete(train_x , outliers, 0)\n",
    "train_y = np.delete(train_y, outliers, 0)\n",
    "data = data.drop(outliers, 0)\n",
    "data = data.reset_index(drop = True)\n",
    "\n",
    "outliers = [102]\n",
    "#print([x for x in test_data['plotid'].iloc[outliers]])\n",
    "\n",
    "train_x = np.delete(train_x , outliers, 0)\n",
    "train_y = np.delete(train_y, outliers, 0)\n",
    "data = data.drop(outliers, 0)\n",
    "data = data.reset_index(drop = True)\n",
    "\n",
    "outliers = [7, 8, 9, 11, 17, 18, 13, 27, 40, 44, 56, 83, 142, ]\n",
    "train_x = np.delete(train_x , outliers, 0)\n",
    "train_y = np.delete(train_y, outliers, 0)\n",
    "data = data.drop(outliers, 0)\n",
    "data = data.reset_index(drop = True)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = np.float32(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_db(x, min_db):\n",
    "    \"\"\"Converts sigma backscatter to decibel\"\"\"\n",
    "    x = 10 * np.log10(x + 1/65535)\n",
    "    x[x < -min_db] = -min_db\n",
    "    x = x + min_db\n",
    "    x = x / min_db\n",
    "    x = np.clip(x, 0, 1)\n",
    "    return x\n",
    "\n",
    "\n",
    "def grndvi(array):\n",
    "    nir = np.clip(array[..., 3], 0, 1)\n",
    "    green = np.clip(array[..., 1], 0, 1)\n",
    "    red = np.clip(array[..., 2], 0, 1)\n",
    "    denominator = (nir+(green+red)) + 1e-5\n",
    "    return (nir-(green+red)) / denominator\n",
    "\n",
    "\n",
    "def evi(x: np.ndarray, verbose: bool = False) -> np.ndarray:\n",
    "    '''\n",
    "    Calculates the enhanced vegetation index\n",
    "    2.5 x (08 - 04) / (08 + 6 * 04 - 7.5 * 02 + 1)\n",
    "    '''\n",
    "\n",
    "    BLUE = x[..., 0]\n",
    "    GREEN = x[..., 1]\n",
    "    RED = x[..., 2]\n",
    "    NIR = x[..., 3]\n",
    "    evis = 2.5 * ( (NIR-RED) / (NIR + (6*RED) - (7.5*BLUE) + 1))\n",
    "    evis = np.clip(evis, -1.5, 1.5)\n",
    "    return evis\n",
    "\n",
    "\n",
    "def msavi2(x: np.ndarray, verbose: bool = False) -> np.ndarray:\n",
    "    '''\n",
    "    Calculates the modified soil-adjusted vegetation index 2\n",
    "    (2 * NIR + 1 - sqrt((2*NIR + 1)^2 - 8*(NIR-RED)) / 2\n",
    "    '''\n",
    "    BLUE = x[..., 0]\n",
    "    GREEN = x[..., 1]\n",
    "    RED = np.clip(x[..., 2], 0, 1)\n",
    "    NIR = np.clip(x[..., 3], 0, 1)\n",
    "\n",
    "    msavis = (2 * NIR + 1 - np.sqrt( (2*NIR+1)**2 - 8*(NIR-RED) )) / 2\n",
    "    return msavis\n",
    "\n",
    "\n",
    "def bi(x: np.ndarray, verbose: bool = False) -> np.ndarray:\n",
    "    \"\"\"Bare soil index\"\"\"\n",
    "    B11 = np.clip(x[..., 8], 0, 1)\n",
    "    B4 = np.clip(x[..., 2], 0, 1)\n",
    "    B8 = np.clip(x[..., 3], 0, 1)\n",
    "    B2 = np.clip(x[..., 0], 0, 1)\n",
    "    bis = ((B11 + B4) - (B8 + B2)) / ((B11 + B4) + (B8 + B2))\n",
    "    return bis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x[..., -1] = convert_to_db(train_x[..., -1], 22)\n",
    "train_x[..., -2] = convert_to_db(train_x[..., -2], 22)\n",
    "\n",
    "indices = np.zeros((train_x.shape[0], 12, 28, 28, 4), dtype = np.float32)\n",
    "indices[..., 0] = evi(train_x)\n",
    "indices[..., 1] = bi(train_x)\n",
    "indices[..., 2] = msavi2(train_x)\n",
    "indices[..., 3] = grndvi(train_x)\n",
    "\n",
    "train_x = np.concatenate([train_x, indices], axis = -1)\n",
    "med = np.median(train_x, axis = 1)\n",
    "med = med[:, np.newaxis, :, :, :]\n",
    "train_x = np.concatenate([train_x, med], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jbrandt.terminal/opt/anaconda3/envs/tf/lib/python3.7/site-packages/ipykernel_launcher.py:14: TqdmDeprecationWarning: Please use `tqdm.notebook.trange` instead of `tqdm.tnrange`\n",
      "  \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0be3f517a36e4bbeb3f0bce5d6202ddd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "min_all = [0.006576638437476157, 0.0162050812542916, 0.010040436408026246, \n",
    "           0.013351644159609368, 0.01965362020294499, 0.014229037918669413, \n",
    "           0.015289539940489814, 0.011993591210803388, 0.008239871824216068, \n",
    "           0.006546120393682765, 0.0, 0.0, 0.0, -0.1409399364817101, \n",
    "           -0.4973397113668104, -0.09731556326714398, -0.7193834232943873]\n",
    "\n",
    "max_all = [0.2691233691920348, 0.3740291447318227, 0.5171435111009385, 0.6027466239414053,\n",
    "           0.5650263218127718, 0.5747005416952773, 0.5933928435187305, 0.6034943160143434, \n",
    "           0.7472037842374304, 0.7000076295109483, 0.509269855802243, 0.948334642387533, \n",
    "           0.6729257769285485, 0.8177635298774327, 0.35768999002433816, 0.7545951919107605, \n",
    "           0.7602693339366691]\n",
    "\n",
    "# Min all, and max all are the 0.1 and 99.9 percentiles of each band\n",
    "for band in tnrange(0, train_x.shape[-1]):\n",
    "    mins = min_all[band]\n",
    "    maxs = max_all[band]\n",
    "    train_x[..., band] = np.clip(train_x[..., band], mins, maxs)\n",
    "    midrange = (maxs + mins) / 2\n",
    "    rng = maxs - mins\n",
    "    standardized = (train_x[..., band] - midrange) / (rng / 2)\n",
    "    train_x[..., band] = standardized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and process test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ntest_x = hkl.load(\"../data/train/train_x.hkl\")\\ntest_y = hkl.load(\"../data/train/train_y.hkl\")\\ntest_data = pd.read_csv(\"../data/train/train_plot_ids.csv\")\\n\\ntest_y = test_y / 255.\\n\\ntest_x = np.delete(test_x, 11, -1)\\n\\nif not isinstance(test_x.flat[0], np.floating):\\n    assert np.max(test_x) > 1\\n    test_x = test_x / 65535.\\n    \\ntest_x[..., -1] = convert_to_db(test_x[..., -1], 22)\\ntest_x[..., -2] = convert_to_db(test_x[..., -2], 22)\\n\\nindices = np.empty((test_x.shape[0], 12, 28, 28, 4))\\nindices[..., 0] = evi(test_x)\\nindices[..., 1] = bi(test_x)\\nindices[..., 2] = msavi2(test_x)\\nindices[..., 3] = grndvi(test_x)\\n\\ntest_x = np.concatenate([test_x, indices], axis = -1)\\nmed = np.median(test_x, axis = 1)\\nmed = med[:, np.newaxis, :, :, :]\\ntest_x = np.concatenate([test_x, med], axis = 1)\\n\\nbelow_1 = [i for i, val in enumerate(test_x[..., :-2]) if np.min(val) < -1.66]\\nabove_1 = [i for i, val in enumerate(test_x[..., :-2]) if np.max(val) > 1.66]\\nnans = [i for i, val in enumerate(test_x) if np.sum(np.isnan(val)) > 0]\\noutliers = below_1 + above_1 + nans\\noutliers = list(set(outliers))\\noutliers = [61, 141, 218, 296, 365, 386, 594, 679, 712, 976, 1909, 2015]\\nprint([x for x in test_data[\\'plotid\\'].iloc[outliers]])\\n\\ntest_x = np.delete(test_x, outliers, 0)\\ntest_y = np.delete(test_y, outliers, 0)\\ntest_data = test_data.drop(outliers, 0)\\ntest_data = test_data.reset_index(drop = True)\\n'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import hickle as hkl\n",
    "\"\"\"\n",
    "test_x = hkl.load(\"../data/train/train_x.hkl\")\n",
    "test_y = hkl.load(\"../data/train/train_y.hkl\")\n",
    "test_data = pd.read_csv(\"../data/train/train_plot_ids.csv\")\n",
    "\n",
    "test_y = test_y / 255.\n",
    "\n",
    "test_x = np.delete(test_x, 11, -1)\n",
    "\n",
    "if not isinstance(test_x.flat[0], np.floating):\n",
    "    assert np.max(test_x) > 1\n",
    "    test_x = test_x / 65535.\n",
    "    \n",
    "test_x[..., -1] = convert_to_db(test_x[..., -1], 22)\n",
    "test_x[..., -2] = convert_to_db(test_x[..., -2], 22)\n",
    "\n",
    "indices = np.empty((test_x.shape[0], 12, 28, 28, 4))\n",
    "indices[..., 0] = evi(test_x)\n",
    "indices[..., 1] = bi(test_x)\n",
    "indices[..., 2] = msavi2(test_x)\n",
    "indices[..., 3] = grndvi(test_x)\n",
    "\n",
    "test_x = np.concatenate([test_x, indices], axis = -1)\n",
    "med = np.median(test_x, axis = 1)\n",
    "med = med[:, np.newaxis, :, :, :]\n",
    "test_x = np.concatenate([test_x, med], axis = 1)\n",
    "\n",
    "below_1 = [i for i, val in enumerate(test_x[..., :-2]) if np.min(val) < -1.66]\n",
    "above_1 = [i for i, val in enumerate(test_x[..., :-2]) if np.max(val) > 1.66]\n",
    "nans = [i for i, val in enumerate(test_x) if np.sum(np.isnan(val)) > 0]\n",
    "outliers = below_1 + above_1 + nans\n",
    "outliers = list(set(outliers))\n",
    "outliers = [61, 141, 218, 296, 365, 386, 594, 679, 712, 976, 1909, 2015]\n",
    "print([x for x in test_data['plotid'].iloc[outliers]])\n",
    "\n",
    "test_x = np.delete(test_x, outliers, 0)\n",
    "test_y = np.delete(test_y, outliers, 0)\n",
    "test_data = test_data.drop(outliers, 0)\n",
    "test_data = test_data.reset_index(drop = True)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfor band in range(0, test_x.shape[-1]):\\n    mins = min_all[band]\\n    maxs = max_all[band]\\n    test_x[..., band] = np.clip(test_x[..., band], mins, maxs)\\n    midrange = (maxs + mins) / 2\\n    rng = maxs - mins\\n    standardized = (test_x[..., band] - midrange) / (rng / 2)\\n    test_x[..., band] = standardized\\n'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "for band in range(0, test_x.shape[-1]):\n",
    "    mins = min_all[band]\n",
    "    maxs = max_all[band]\n",
    "    test_x[..., band] = np.clip(test_x[..., band], mins, maxs)\n",
    "    midrange = (maxs + mins) / 2\n",
    "    rng = maxs - mins\n",
    "    standardized = (test_x[..., band] - midrange) / (rng / 2)\n",
    "    test_x[..., band] = standardized\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Equibatch creation\n",
    "\n",
    "The modelling approach uses equibatch sampling to ensure that there is a near constant standard deviation of the percent tree cover in the output labels for each batch. This helps ensure that the model performs equally well across gradients of tree cover, by mitigating the random possibility that many batches in a row near the end of sampling may be randomly biased towards a tree cover range.\n",
    "\n",
    "It was actually very important for stable training to implement equibatch as the risk of diverging based on bad batches was very high without equibatch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ids = [x for x in range(0, len(train_y))]\n",
    "\n",
    "def multiplot(matrices):\n",
    "    '''Plot multiple heatmaps with subplots\n",
    "    \n",
    "         Parameters:\n",
    "          matrices (list of arrays):\n",
    "\n",
    "         Returns:\n",
    "          None\n",
    "    '''\n",
    "    fig, axs = plt.subplots(ncols=4)\n",
    "    fig.set_size_inches(20, 4)\n",
    "    for i, matrix in enumerate(matrices):\n",
    "        sns.heatmap(data = matrix, ax = axs[i], vmin = 0, vmax = 0.9)\n",
    "        axs[i].set_xlabel(\"\")\n",
    "        axs[i].set_ylabel(\"\")\n",
    "        axs[i].set_yticks([])\n",
    "        axs[i].set_xticks([])\n",
    "\n",
    "        \n",
    "def equibatch(train_ids):\n",
    "    '''Docstring\n",
    "    \n",
    "         Parameters:\n",
    "          train_ids (list):\n",
    "          p (list):\n",
    "\n",
    "         Returns:\n",
    "          equibatches (list):\n",
    "    '''\n",
    "    \n",
    "    # Percents is the upper, lower bounds for each segment of equibatch\n",
    "    percents = [9.0, 17.0, 27.0, 40.0, 63.0, 105.0, 158.0]\n",
    "    #train2 = train_ids[-30:] * 20\n",
    "\n",
    "    train_ids_cp = (train_ids) #+ train2\n",
    "    np.random.shuffle(train_ids_cp)\n",
    "    ix = train_ids_cp\n",
    "    percs = [np.sum(x) for x in train_y[ix]]\n",
    "    ids0 = [x for x, z in zip(ix, percs) if z <= 2]\n",
    "    ids30 = [x for x, z in zip(ix, percs) if 2 < z <= percents[0]]\n",
    "    ids40 = [x for x, z in zip(ix, percs) if percents[0] < z <= percents[1]]\n",
    "    ids50 = [x for x, z in zip(ix, percs) if percents[1] < z <= percents[2]]\n",
    "    ids60 = [x for x, z in zip(ix, percs) if percents[2] < z <= percents[3]]\n",
    "    ids70 = [x for x, z in zip(ix, percs) if percents[3] < z <= percents[4]]\n",
    "    ids80 = [x for x, z in zip(ix, percs) if percents[4] < z <= percents[5]]\n",
    "    ids90 = [x for x, z in zip(ix, percs) if percents[5] < z <= percents[6]]\n",
    "    ids100 = [x for x, z in zip(ix, percs) if percents[6] < z]\n",
    "    \n",
    "    new_batches = []\n",
    "    maxes = [len(ids0), len(ids30), len(ids40), len(ids50), len(ids60), len(ids70),\n",
    "             len(ids80), len(ids90), len(ids100)]\n",
    "    print(maxes)\n",
    "    # This essentially picks one of each segment of equibatch for each time\n",
    "    # samples are appended to the shuffled training data batch\n",
    "    cur_ids = [0] * len(maxes)\n",
    "    iter_len = len(train_ids)//(len(maxes))\n",
    "    for i in range(0, iter_len):\n",
    "        for i, val in enumerate(cur_ids):\n",
    "            if val > maxes[i] - 1:\n",
    "                cur_ids[i] = 0\n",
    "        if cur_ids[0] >= (maxes[0] - 2):\n",
    "            cur_ids[0] = 0\n",
    "        to_append = [ids0[cur_ids[0]],\n",
    "                    ids30[cur_ids[1]], ids40[cur_ids[2]],\n",
    "                    ids50[cur_ids[3]], ids60[cur_ids[4]], \n",
    "                    ids70[cur_ids[5]], ids80[cur_ids[6]],\n",
    "                    ids90[cur_ids[7]], ids100[cur_ids[8]]]\n",
    "        \n",
    "        \n",
    "        np.random.shuffle(to_append)\n",
    "        new_batches.append(to_append)\n",
    "        cur_ids = [x + 1 for x in cur_ids]\n",
    "        \n",
    "    new_batches = [item for sublist in new_batches for item in sublist]\n",
    "    return new_batches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_f1_score_at_tolerance(true, pred, tolerance = 1):\n",
    "    \"\"\"Because of coregistration errors, we evaluate the model\n",
    "    where false positives/negatives must be >1px away from a true positive\n",
    "    \"\"\"\n",
    "    fp = 0\n",
    "    tp = 0\n",
    "    fn = 0\n",
    "    \n",
    "    tp = np.zeros_like(true)\n",
    "    fp = np.zeros_like(true)\n",
    "    fn = np.zeros_like(true)\n",
    "    \n",
    "    for x in range(true.shape[0]):\n",
    "        for y in range(true.shape[1]):\n",
    "            min_x = np.max([0, x-1])\n",
    "            min_y = np.max([0, y-1])\n",
    "            max_y = np.min([true.shape[0], y+2])\n",
    "            max_x = np.min([true.shape[0], x+2])\n",
    "            if true[x, y] == 1:\n",
    "                if np.sum(pred[min_x:max_x, min_y:max_y]) > 0:\n",
    "                    tp[x, y] = 1\n",
    "                else:\n",
    "                    fn[x, y] = 1\n",
    "            if pred[x, y] == 1:\n",
    "                if np.sum(true[min_x:max_x, min_y:max_y]) > 0:\n",
    "                    if true[x, y] == 1:\n",
    "                        tp[x, y] = 1\n",
    "                else:\n",
    "                    fp[x, y] = 1                \n",
    "                \n",
    "    return np.sum(tp), np.sum(fp), np.sum(fn)\n",
    "\n",
    "def calculate_metrics(al = 0.4, canopy_thresh = 100):\n",
    "    '''Calculates the following metrics\n",
    "       \n",
    "         - Loss\n",
    "         - F1\n",
    "         - Precision\n",
    "         - Recall\n",
    "         - Dice\n",
    "         - Mean surface distance\n",
    "         - Average error\n",
    "    \n",
    "         Parameters:\n",
    "          al (float):\n",
    "          canopy_thresh (int)\n",
    "          \n",
    "         Returns:\n",
    "          val_loss (float):\n",
    "          best_dice (float):\n",
    "          error (float):\n",
    "    '''\n",
    "    start_idx = 0\n",
    "    stop_idx = len(test_x)\n",
    "    best_f1, best_thresh, relaxed_f1 = 0, 0, 0\n",
    "    preds, trues, vls = [], [], []\n",
    "\n",
    "    test_ids = [x for x in range(len(test_x))]\n",
    "    for test_sample in test_ids[start_idx:stop_idx]:\n",
    "        if np.sum(test_y[test_sample]) < ((canopy_thresh/100) * 197):\n",
    "            x_input = test_x[test_sample].reshape(1, 13, 28, 28, n_bands)\n",
    "            x_median_input = calc_median_input(x_input)\n",
    "            y, vl = sess.run([fm, test_loss], feed_dict={inp: x_input,\n",
    "                                                          length: np.full((1,), 12),\n",
    "                                                          is_training: False,\n",
    "                                                          labels: test_y[test_sample].reshape(1, 14, 14),\n",
    "                                                          loss_weight: 1.0,\n",
    "                                                          alpha: 0.33,\n",
    "                                                          })\n",
    "            preds.append(y.reshape((14, 14)))\n",
    "            vls.append(vl)\n",
    "            trues.append(test_y[test_sample].reshape((14, 14)))\n",
    "            \n",
    "    # These threshes are just for ROC\n",
    "    for thresh in range(7, 9):\n",
    "        tps_relaxed = np.empty((len(preds), ))\n",
    "        fps_relaxed = np.empty((len(preds), ))\n",
    "        fns_relaxed = np.empty((len(preds), ))\n",
    "        abs_error = np.empty((len(preds), ))\n",
    "        \n",
    "        for sample in range(len(preds)):\n",
    "            pred = np.copy(preds[sample])\n",
    "            true = trues[sample]\n",
    "        \n",
    "            pred[np.where(pred >= thresh*0.05)] = 1\n",
    "            pred[np.where(pred < thresh*0.05)] = 0\n",
    "            \n",
    "            true_s = np.sum(true[1:-1])\n",
    "            pred_s = np.sum(pred[1:-1])\n",
    "            abs_error[sample] = abs(true_s - pred_s)\n",
    "            tp_relaxed, fp_relaxed, fn_relaxed = compute_f1_score_at_tolerance(true, pred)\n",
    "            tps_relaxed[sample] = tp_relaxed\n",
    "            fps_relaxed[sample] = fp_relaxed\n",
    "            fns_relaxed[sample] = fn_relaxed                   \n",
    "            \n",
    "        oa_error = np.mean(abs_error)\n",
    "        precision_r = np.sum(tps_relaxed) / (np.sum(tps_relaxed) + np.sum(fps_relaxed))\n",
    "        recall_r = np.sum(tps_relaxed) / (np.sum(tps_relaxed) + np.sum(fns_relaxed))\n",
    "        f1_r = 2*((precision_r* recall_r) / (precision_r + recall_r))\n",
    "        \n",
    "        if f1_r > best_f1:\n",
    "            best_f1 = f1_r\n",
    "            p = precision_r\n",
    "            r = recall_r\n",
    "            error = oa_error\n",
    "            best_thresh = thresh*0.05\n",
    "\n",
    "    print(f\"Val loss: {np.around(np.mean(vls), 3)}\"\n",
    "          f\" Thresh: {np.around(best_thresh, 2)}\"\n",
    "          f\" F1: {np.around(best_f1, 3)} R: {np.around(p, 3)} P: {np.around(r, 3)}\"\n",
    "          f\" Error: {np.around(error, 3)}\")\n",
    "    return np.mean(vls), best_f1, error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below code block implements cut mix where random samples are spliced together where the output labels have similar tree cover distributions (within the same kmeans cluster). Not super necessary but does give a small performance improvement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "#x_med = np.median(train_x, axis = (1, 2, 3))\n",
    "#kmeans = KMeans(n_clusters=10, random_state=0).fit(x_med)\n",
    "#clusters = kmeans.labels_\n",
    "\n",
    "def fftIndgen(n):\n",
    "    a = range(0, n//2+1)\n",
    "    b = range(1, n//2)\n",
    "    b = [x for x in b]\n",
    "    b.reverse()\n",
    "    a = [x for x in a]\n",
    "   \n",
    "    b = [-i for i in b]\n",
    "    return a + b\n",
    "\n",
    "\n",
    "def gaussian_random_field(Pk = lambda k : k**-3.0, size = 100):\n",
    "    def Pk2(kx, ky):\n",
    "        if kx == 0 and ky == 0:\n",
    "            return 0.0\n",
    "        return np.sqrt(Pk(np.sqrt(kx**2 + ky**2)))\n",
    "    noise = np.fft.fft2(np.random.normal(size = (size, size)))\n",
    "    amplitude = np.zeros((size,size))\n",
    "    for i, kx in enumerate(fftIndgen(size)):\n",
    "        for j, ky in enumerate(fftIndgen(size)):            \n",
    "            amplitude[i, j] = Pk2(kx, ky)\n",
    "    return np.fft.ifft2(noise * amplitude).astype(np.float32)\n",
    "\n",
    "\n",
    "def make_aug_masks(n, perc):\n",
    "    masks = np.zeros((n, 24, 24))\n",
    "    for i in range(n):\n",
    "        gas = gaussian_random_field(Pk = lambda k: k**-5, size=24)\n",
    "        percentile = np.clip(np.random.normal(perc, 0.1, 1), 0, 1)\n",
    "        percentile = np.percentile(gas, percentile * 100)\n",
    "        gas = gas <= percentile\n",
    "        masks[i] = gas\n",
    "    return masks\n",
    "\n",
    "\n",
    "def cut_mix(x_batch, y_batch, ids, percent, batch_size, clusters):\n",
    "    \n",
    "    train_ids = [x for x in range(len(train_x))]\n",
    "    cl_batch = clusters[ids]\n",
    "    \n",
    "    binary_mask = np.random.rand(batch_size)\n",
    "    binary_mask = (binary_mask <= 0.25).astype(np.int)\n",
    "    \n",
    "    masks_x = make_aug_masks(batch_size, .33)\n",
    "    masks_y = masks_x[:, 5:-5, 5:-5]\n",
    "    masks_x = np.broadcast_to(\n",
    "        masks_x[:, np.newaxis, :, :, np.newaxis], (batch_size, 13, 24, 24, 17))\n",
    "    \n",
    "    i = 0\n",
    "    for x, y, cluster, mask in zip(x_batch, y_batch, cl_batch, binary_mask):\n",
    "        if mask == 1:\n",
    "            random_id = np.random.choice(clusters[clusters == cluster])\n",
    "            x_random = train_x[random_id]\n",
    "            y_random = train_y[random_id]\n",
    "\n",
    "            x[masks_x[i] == 1] = x_random[masks_x[i] == 1]\n",
    "            y[masks_y[i] == 1] = y_random[masks_y[i] == 1]\n",
    "            i += 1\n",
    "\n",
    "    return x_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_batch(batch_ids, batch_size):\n",
    "    '''Performs random flips and rotations of the X and Y\n",
    "       data, cut mix, and random splicing of the temporal data\n",
    "    \n",
    "         Parameters:\n",
    "          batch_ids (list):\n",
    "          batch_size (int):\n",
    "          \n",
    "         Returns:\n",
    "          x_batch (arr):\n",
    "          y_batch (arr):\n",
    "    '''\n",
    "    x = train_x[batch_ids]\n",
    "    samples_to_median = np.random.randint(0, 12, size=(batch_size, 6))\n",
    "    n_samples = np.random.randint(2, 7, size=(batch_size))\n",
    "    for samp in range(batch_size):\n",
    "        samps = samples_to_median[samp, :np.random.randint(2, 6)]\n",
    "        lower_samp = np.min(samps)\n",
    "        upper_samp = np.max(samps)\n",
    "        med_samp = np.median(x[samp, samps], axis = 0)\n",
    "        \n",
    "        x[samp, :lower_samp] = x[samp, lower_samp]\n",
    "        x[samp, upper_samp:] = x[samp, upper_samp]\n",
    "        x[samp, -1, ...] = med_samp\n",
    "        \n",
    "    y = train_y[batch_ids]\n",
    "    x_batch = np.zeros_like(x)\n",
    "    y_batch = np.zeros_like(y)\n",
    "    \n",
    "    flips = np.random.choice(np.array([0, 1, 2, 3]), batch_size, replace = True)\n",
    "    for i in range(x.shape[0]):\n",
    "        current_flip = flips[i]\n",
    "        if current_flip == 0:\n",
    "            x_batch[i] = x[i]\n",
    "            y_batch[i] = y[i]\n",
    "        if current_flip == 1:\n",
    "            x_batch[i] = np.flip(x[i], 1)\n",
    "            y_batch[i] = np.flip(y[i], 0)\n",
    "        if current_flip == 2:\n",
    "            x_batch[i] = np.flip(x[i], [2, 1])\n",
    "            y_batch[i] = np.flip(y[i], [1, 0])\n",
    "        if current_flip == 3:\n",
    "            x_batch[i] = np.flip(x[i], 2)\n",
    "            y_batch[i] = np.flip(y[i], 1)\n",
    "\n",
    "    y_batch = y_batch.reshape((batch_size, 14, 14))\n",
    "    #x_batch, y_batch = cut_mix(x_batch, y_batch, batch_ids, 0.5, batch_size)\n",
    "    return x_batch, y_batch\n",
    "\n",
    "x_batch_test, y_batch_test = augment_batch([x for x in range(4)], 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x864 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "start = 75\n",
    "end = 125\n",
    "f, ((c1r1, c1r2), (c2r1, c2r2)) = plt.subplots(2, 2, sharey=False)\n",
    "f.set_size_inches(15, 12)\n",
    "\n",
    "c1r1.set_title(f\"Train loss - {model_path}\")\n",
    "l1 = sns.scatterplot(y = metrics[0, start:end], x = np.arange(start, end), ax = c1r1)\n",
    "l1.set(ylim=(0.30, .40))\n",
    "\n",
    "c1r2.set_title(\"F1 score\")\n",
    "f =sns.scatterplot(y = metrics[5, start:end], x = np.arange(start, end), ax = c1r2)\n",
    "f.set(ylim=(0.84, .91))\n",
    "\n",
    "c2r1.set_title(\"Test loss\")\n",
    "l = sns.scatterplot(y = metrics[1, start:end], x = np.arange(start, end), ax = c2r1)\n",
    "l.set(ylim=(0.140, .165)) \n",
    "\n",
    "c2r2.set_title(\"Absolute % error\")\n",
    "e = sns.scatterplot(y = metrics[2, start:end] / 2, x = np.arange(start, end), ax = c2r2)\n",
    "e.set(ylim=(2.2, 3.5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3897\n",
      "starting epoch 120, alpha: 0.33, beta: 0.0, drop: 0.9 Learning rate: 0.02\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc19e5d19835497aa030e9d96b201e1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/487 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jbrandt.terminal/opt/anaconda3/envs/tf/lib/python3.7/site-packages/ipykernel_launcher.py:48: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 120: Loss 0.032999999821186066\n",
      "3897\n",
      "starting epoch 121, alpha: 0.33, beta: 0.0, drop: 0.9 Learning rate: 0.02\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8164fcd24159461cbaeb81ded5a67fe4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/487 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 121: Loss 0.03099999949336052\n",
      "3897\n",
      "starting epoch 122, alpha: 0.33, beta: 0.0, drop: 0.9 Learning rate: 0.02\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecbd34a805964835a7fc830b70487b7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/487 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 122: Loss 0.032999999821186066\n",
      "3897\n",
      "starting epoch 123, alpha: 0.33, beta: 0.0, drop: 0.9 Learning rate: 0.02\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "701e739a92e64ec89f88b30023cf3332",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/487 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 123: Loss 0.029999999329447746\n",
      "3897\n",
      "starting epoch 124, alpha: 0.33, beta: 0.0, drop: 0.9 Learning rate: 0.02\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "418c903f12e64f65a5537a2597171a10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/487 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 124: Loss 0.03200000151991844\n",
      "3897\n",
      "starting epoch 125, alpha: 0.33, beta: 0.0, drop: 0.9 Learning rate: 0.02\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "107c0882c9d6494cbbdb68eeae3218f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/487 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 125: Loss 0.03400000184774399\n",
      "3897\n",
      "starting epoch 126, alpha: 0.33, beta: 0.0, drop: 0.9 Learning rate: 0.02\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "169cf3e8b1684f90926e8b2ed63dc58e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/487 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 126: Loss 0.03200000151991844\n",
      "3897\n",
      "starting epoch 127, alpha: 0.33, beta: 0.0, drop: 0.9 Learning rate: 0.02\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94d6308f7c8041dca68b9ae31bb2de8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/487 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 127: Loss 0.03200000151991844\n",
      "3897\n",
      "starting epoch 128, alpha: 0.33, beta: 0.0, drop: 0.9 Learning rate: 0.02\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71ca5eaf467f48c99299a4ebb671d0d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/487 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 128: Loss 0.03099999949336052\n",
      "3897\n",
      "starting epoch 129, alpha: 0.33, beta: 0.0, drop: 0.9 Learning rate: 0.02\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bc2ab934e494c0cae4afa561bf15f23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/487 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 129: Loss 0.03200000151991844\n"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "\n",
    "best_val = 0.72\n",
    "fine_tune = False\n",
    "ft_epochs = 0\n",
    "BATCH_SIZE = 8\n",
    "\n",
    "\n",
    "\n",
    "for i in range(120, 130):\n",
    "    if i >= 120:\n",
    "        SWA = True# set to true to start SWA\n",
    "    else:\n",
    "        SWA = False\n",
    "    al = FINAL_ALPHA\n",
    "    #al = np.min([0.01 * (i - 1), FINAL_ALPHA])\n",
    "    ft_learning_rate = .02\n",
    "    be = 0.0\n",
    "    test_al = al\n",
    "    op = train_op# if fine_tune else train_op\n",
    "        \n",
    "    train_ids = [x for x in range(len(train_y))]\n",
    "    #train_ids = train_ids + train_ids[-76:]\n",
    "    print(len(train_ids))\n",
    "    #train_ids_cp = (train_ids)\n",
    "    np.random.shuffle(train_ids)\n",
    "    randomize = train_ids\n",
    "    #randomize = equibatch(train_ids, 0)\n",
    "    print(f\"starting epoch {i}, \" \n",
    "          f\"alpha: {al}, beta: {be}, \"\n",
    "          f\"drop: {np.max(((1. - (i * 0.005)), 0.9))} \"\n",
    "          f\"Learning rate: {ft_learning_rate}\"\n",
    "         )\n",
    "    \n",
    "    loss = train_loss\n",
    "    #test_ids = [x for x in range(0, len(test_x))]\n",
    "    losses = []\n",
    "    \n",
    "    for k in tqdm.notebook.tnrange(int(len(randomize) // BATCH_SIZE)):\n",
    "        batch_ids = randomize[k*BATCH_SIZE:(k+1)*BATCH_SIZE]\n",
    "        x_batch, y_batch = augment_batch(batch_ids, BATCH_SIZE)\n",
    "        #print(np.sum(np.sum(y_batch, axis = (1, 2)) <= 2))\n",
    "        opt, tr = sess.run([op, loss],\n",
    "                          feed_dict={inp: x_batch,\n",
    "                                     length: np.full((BATCH_SIZE,), 12),\n",
    "                                     labels: y_batch,\n",
    "                                     is_training: True,\n",
    "                                     loss_weight: 1.0,\n",
    "                                     keep_rate: 0.95,#np.max(((1. - (i * 0.01)), MAX_DROPBLOCK)),\n",
    "                                     alpha: al,\n",
    "                                     beta_: be,\n",
    "                                     ft_lr: ft_learning_rate,\n",
    "                                     })\n",
    "        losses.append(tr)\n",
    "    \n",
    "    print(f\"Epoch {i}: Loss {np.around(np.mean(losses[:-1]), 3)}\")\n",
    "    if SWA:\n",
    "        sess.run(swa_op)\n",
    "        sess.run(save_weight_backups)\n",
    "        sess.run(swa_to_weights)\n",
    "        \n",
    "    #metrics[0, i] = np.mean(losses[:-1])\n",
    "    #val_loss, f1, error = calculate_metrics('all', al = test_al, canopy_thresh = 75)\n",
    "    #metrics[1, i] = val_loss\n",
    "    #metrics[2, i] = error\n",
    "    #metrics[5, i] = f1\n",
    "    \n",
    "    #if f1 < (best_val - 0.002):\n",
    "    #    ft_epochs += 1\n",
    "        \n",
    "    #if f1 > (best_val - 0.02):\n",
    "    #    print(f\"Saving model with {f1}\")\n",
    "        #np.save(f\"{model_path}metrics.npy\", metrics)\n",
    "        #os.mkdir(f\"{model_path}{str(i)}-{str(f1*100)[:2]}-{str(f1*100)[3]}/\")\n",
    "        #save_path = saver.save(sess, f\"{model_path}/{str(i)}-{str(f1*100)[:2]}-{str(f1*100)[3]}/model\")\n",
    "     #   if f1 > best_val:\n",
    "     #       best_val = f1\n",
    "    if SWA:\n",
    "        sess.run(restore_weight_backups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sess.run(restore_weight_backups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.run(swa_to_weights)\n",
    "saver = tf.train.Saver(max_to_keep = 150)\n",
    "#os.mkdir(f\"../models/regressor2/\")\n",
    "save_path = saver.save(sess, f\"../models/regressor2/model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Froze 65 variables.\n",
      "INFO:tensorflow:Converted 65 variables to const ops.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "output_node_names = ['conv2d_13/Sigmoid']\n",
    "frozen_graph_def = tf.graph_util.convert_variables_to_constants(\n",
    "    sess,\n",
    "    sess.graph_def,\n",
    "    output_node_names)\n",
    "\n",
    "\n",
    "# Save the frozen graph\n",
    "with open('../models/regressor2/predict_graph.pb', 'wb') as f:\n",
    "    f.write(frozen_graph_def.SerializeToString())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test prediction visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "start =0\n",
    "#test_ids = [x for x in range(0, len(test_x))]\n",
    "\n",
    "def multiplot(matrices, nrows = 2, ncols = 4):\n",
    "    '''Docstring\n",
    "    \n",
    "         Parameters:\n",
    "          matrices (list):\n",
    "          nrows (int):\n",
    "          \n",
    "         Returns:\n",
    "          None\n",
    "    '''\n",
    "    fig, axs = plt.subplots(ncols=4, nrows = nrows)\n",
    "    fig.set_size_inches(18, 4*nrows)\n",
    "    to_iter = [[x for x in range(i, i + ncols + 1)] for i in range(0, nrows*ncols, ncols)]\n",
    "    for r in range(1, nrows + 1):\n",
    "        min_i = min(to_iter[r-1])\n",
    "        max_i = max(to_iter[r-1])\n",
    "        for i, matrix in enumerate(matrices[min_i:max_i]):\n",
    "            sns.heatmap(data = matrix, ax = axs[r - 1, i], vmin = 0, vmax = 0.9, cbar = False)\n",
    "            axs[r - 1, i].set_xlabel(\"\")\n",
    "            axs[r - 1, i].set_ylabel(\"\")\n",
    "            axs[r - 1, i].set_yticks([])\n",
    "            axs[r - 1, i].set_xticks([])\n",
    "    plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ids = [x for x in range(test_x.shape[0])]\n",
    "matrix_ids = np.arange(start, start + 8, 1)\n",
    "matrix_ids = test_ids[matrix_ids]\n",
    "preds, trues = [], []\n",
    "\n",
    "for i in matrix_ids:\n",
    "    idx = i\n",
    "    x_input = test_x[idx].reshape(1, 13, 28, 28, n_bands)\n",
    "    median_input = calc_median_input(x_input)\n",
    "    y = sess.run([fm], feed_dict={inp: x_input,\n",
    "                                  length: np.full((1,), 12),\n",
    "                                  is_training: False,\n",
    "                                  })\n",
    "    y = np.array(y).reshape(14, 14)\n",
    "    print(i, (list(test_data.iloc[idx, 1])[0], list(test_data.iloc[idx, 2])[0]), diffs[i[0]])\n",
    "    preds.append(y)\n",
    "    y2 = np.copy(y)\n",
    "    true = tes\n",
    "    t_y[idx].reshape(14, 14)\n",
    "    trues.append(true)\n",
    "\n",
    "to_plot = trues[0:4] + preds[0:4] + trues[4:] + preds[4:]\n",
    "multiplot(to_plot, nrows = 4, ncols = 4)\n",
    "\n",
    "start = start + 8 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i ini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train prediction visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = 1950\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2032 , 2036\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2014 2015 2016 2017 2018 2019 2020 2021]\n",
      "0.47 39.017376 -6.227906\n",
      "0.48 37.44056 -107.45501\n",
      "0.22 -7.9574475 -39.19353\n",
      "0.25 28.134605 -110.021454\n",
      "0.33 -25.08411 148.0342\n",
      "0.37 38.11405 -4.9022045\n",
      "0.25 13.039986 -8.702612\n",
      "0.47 -22.908873 150.68954\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x1152 with 16 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_ids = np.array([x for x in range(train_x.shape[0])])\n",
    "#start = len(train_ids) - 84\n",
    "\n",
    "matrix_ids = np.arange(start, start + 8, 1)\n",
    "matrix_ids = train_ids[matrix_ids]\n",
    "preds, trues = [], []\n",
    "\n",
    "print(matrix_ids)\n",
    "for i in matrix_ids:\n",
    "    idx = i\n",
    "    x_input = train_x[idx].reshape(1, 13, 28, 28, n_bands)\n",
    "    y = sess.run([fm], feed_dict={inp: x_input,\n",
    "                                  length: np.full((1,), 12),\n",
    "                                  is_training: False,\n",
    "                                    })\n",
    "    #print(np.sum(np.isnan(y)))\n",
    "    y = np.array(y).reshape(14, 14)  \n",
    "    #y = nplogit(y)\n",
    "    preds.append(y)\n",
    "    true = train_y[idx].reshape(14, 14)\n",
    "    trues.append(true)\n",
    "    print(np.\n",
    "          around(np.mean(y) - np.mean(true), 2), data.iloc[i].lat, data.iloc[i].lon)\n",
    "    \n",
    "start += 8\n",
    "to_plot = trues[0:4] + preds[0:4] + trues[4:] + preds[4:]\n",
    "multiplot(to_plot, nrows = 4, ncols = 4)\n",
    "# 2006, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "plotid                                                   6937060010.0\n",
       "lat                                                        -16.636393\n",
       "lon                                                          20.97607\n",
       "gedi_rh95                                                         7.9\n",
       "filename            image_tile44264a22-62d6-4cd6-b1f9-2a0d4f86846f...\n",
       "tp                                                                0.0\n",
       "fp                                                                0.0\n",
       "fn                                                                0.0\n",
       "fn_ground                                                         0.0\n",
       "subregion                                               Middle Africa\n",
       "gedi_gte5                                                         1.0\n",
       "label                                                             0.0\n",
       "pred                                                        15.541606\n",
       "error                                                       15.541606\n",
       "tile_acq_date                                                 9/21/18\n",
       "mislabel                                                           No\n",
       "Unnamed: 0                                                     5690.0\n",
       "gedi_shot_number                                  69400000000000000.0\n",
       "job_id                                              459000000000000.0\n",
       "gedi_delta_time                                            68503892.0\n",
       "tile_delta_time                                            22723200.0\n",
       "precision                                                         0.0\n",
       "recall                                                            0.0\n",
       "iou_tree                                                          0.0\n",
       "iou_ground                                                        1.0\n",
       "iou_macro                                                         0.5\n",
       "tp_ground                                                     65536.0\n",
       "fp_ground                                                         0.0\n",
       "Name: 2114, dtype: object"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.iloc[2114]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(abs(y - train_y[1136]) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(train_y[1136])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = 1132"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_ids = np.array([x for x in range(train_x.shape[0])])\n",
    "start = len(train_ids) - 8\n",
    "\n",
    "matrix_ids = np.arange(start, start + 8, 1)\n",
    "matrix_ids = train_ids[matrix_ids]\n",
    "preds, trues = [], []\n",
    "\n",
    "print(matrix_ids)\n",
    "for i in matrix_ids:\n",
    "    idx = i\n",
    "    x_input = train_x[idx].reshape(1, 13, 28, 28, n_bands)\n",
    "    y = sess.run([output], feed_dict={inp: x_input,\n",
    "                                  length: np.full((1,), 12),is_training: False,\n",
    "                                    })\n",
    "    #print(np.sum(np.isnan(y)))\n",
    "    y = np.array(y).reshape(14, 14)  \n",
    "    y = np.clip(y, 0, 1)\n",
    "    #y = nplogit(y)\n",
    "    preds.append(y)\n",
    "    true = train_y[idx].reshape(14, 14)\n",
    "    trues.append(true)\n",
    "    print(np.around(np.mean(y) - np.mean(true), 2), data.iloc[i].lat, data.iloc[i].lon)\n",
    "    \n",
    "start += 8\n",
    "\n",
    "to_plot = trues[0:4] + preds[0:4] + trues[4:] + preds[4:]\n",
    "multiplot(to_plot, nrows = 4, ncols = 4)\n",
    "# 7, 8, 9, 11, 17, 18, 13, 27, 40, 44, 56, 83, 142, \n",
    "#[102]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ids = np.array([x for x in range(train_x.shape[0])])\n",
    "start = 1297\n",
    "\n",
    "matrix_ids = np.arange(start, start + 8, 1)\n",
    "matrix_ids = train_ids[matrix_ids]\n",
    "preds, trues = [], []\n",
    "\n",
    "print(matrix_ids)\n",
    "for i in matrix_ids:\n",
    "    idx = i\n",
    "    x_input = train_x[idx].reshape(1, 13, 28, 28, n_bands)\n",
    "    y = sess.run([fm], feed_dict={inp: x_input,\n",
    "                                  length: np.full((1,), 12),\n",
    "                                  is_training: False,\n",
    "                                    })\n",
    "    y = np.array(y).reshape(14, 14)    \n",
    "    preds.append(y)\n",
    "    true = train_y[idx].reshape(14, 14)\n",
    "    trues.append(true)\n",
    "    \n",
    "start += 8\n",
    "to_plot = trues[0:4] + preds[0:4] + trues[4:] + preds[4:]\n",
    "multiplot(to_plot, nrows = 4, ncols = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gru.trainable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
